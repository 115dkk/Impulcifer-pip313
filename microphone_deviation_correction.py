# -*- coding: utf-8 -*-
"""
êµì°¨ê²€ì¦ ê¸°ë°˜ ë§ˆì´í¬ ì°©ìš© í¸ì°¨ ë³´ì • (v3.0)

í•µì‹¬ ì›ë¦¬:
- ë§ˆì´í¬ ì˜¤ì°¨: ëª¨ë“  ìŠ¤í”¼ì»¤ ë°©í–¥ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì¢Œìš° ì°¨ì´
- HRTF ë¹„ëŒ€ì¹­: ìŠ¤í”¼ì»¤ ë°©í–¥ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ë³€í•˜ëŠ” ì¢Œìš° ì°¨ì´

ì´ ë‘ ì„±ë¶„ì„ í†µê³„ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë§ˆì´í¬ ì˜¤ì°¨ë§Œ ë³´ì •í•©ë‹ˆë‹¤.

v3.0 ë³€ê²½ì‚¬í•­:
- êµì°¨ê²€ì¦ ë¡œì§ ë„ì…: ëª¨ë“  ìŠ¤í”¼ì»¤ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì •
- ìœ„ìƒ ë³´ì • ì œê±°: minimum_phase + ìœ„ìƒ ë³´ì •ì˜ êµ¬ì¡°ì  ëª¨ìˆœ í•´ê²°
- í•´ë¶€í•™ì  ì„ í—˜ ì§€ì‹ í™œìš©: ìŠ¤í”¼ì»¤ ë°©í–¥ë³„ ê¸°ëŒ€ ILD ë¶€í˜¸ ì‚¬ìš©
- ì¼ê´€ì„± ê²€ì¦: ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨ì˜ ë¬¼ë¦¬ì  íƒ€ë‹¹ì„± ê²€ì¦
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from scipy import signal
from scipy.fft import fft, fftfreq
from scipy.interpolate import interp1d
from autoeq.frequency_response import FrequencyResponse
import warnings


class CrossValidatedMicrophoneCorrector:
    """
    ë‹¤ì¤‘ ìŠ¤í”¼ì»¤ êµì°¨ê²€ì¦ ê¸°ë°˜ ë§ˆì´í¬ í¸ì°¨ ë³´ì • (v3.0)

    í•µì‹¬ ì›ë¦¬:
    - ë§ˆì´í¬ ì˜¤ì°¨: ëª¨ë“  ìŠ¤í”¼ì»¤ ë°©í–¥ì—ì„œ ì¼ê´€ë˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì¢Œìš° ì°¨ì´
    - HRTF ë¹„ëŒ€ì¹­: ìŠ¤í”¼ì»¤ ë°©í–¥ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ë³€í•˜ëŠ” ì¢Œìš° ì°¨ì´

    ì´ ë‘ ì„±ë¶„ì„ í†µê³„ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë§ˆì´í¬ ì˜¤ì°¨ë§Œ ë³´ì •í•©ë‹ˆë‹¤.
    """

    def __init__(self, sample_rate,
                 correction_strength=0.7,
                 octave_bands=None,
                 max_correction_db=6.0,
                 min_gate_cycles=2,
                 max_gate_cycles=8):
        """
        Args:
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
            correction_strength (float): ë³´ì • ê°•ë„ (0.0~1.0)
            octave_bands (list): ë¶„ì„í•  ì˜¥íƒ€ë¸Œ ë°´ë“œ ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ë“¤ (Hz)
            max_correction_db (float): ìµœëŒ€ ë³´ì •ëŸ‰ (dB)
            min_gate_cycles (float): ìµœì†Œ ê²Œì´íŠ¸ ê¸¸ì´ (ì‚¬ì´í´ ìˆ˜)
            max_gate_cycles (float): ìµœëŒ€ ê²Œì´íŠ¸ ê¸¸ì´ (ì‚¬ì´í´ ìˆ˜)
        """
        self.fs = sample_rate
        self.correction_strength = np.clip(correction_strength, 0.0, 1.0)
        self.max_correction_db = max_correction_db
        self.min_gate_cycles = min_gate_cycles
        self.max_gate_cycles = max_gate_cycles

        # ê¸°ë³¸ ì˜¥íƒ€ë¸Œ ë°´ë“œ ì„¤ì • (250Hz ~ 8kHz - ë§ˆì´í¬ í¸ì°¨ê°€ ì£¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ëŒ€ì—­)
        if octave_bands is None:
            self.octave_bands = [250, 500, 1000, 2000, 4000, 8000]
        else:
            self.octave_bands = octave_bands

        # ë‚˜ì´í€´ìŠ¤íŠ¸ ì£¼íŒŒìˆ˜ ì´í•˜ë¡œ ì œí•œ
        self.octave_bands = [f for f in self.octave_bands if f < self.fs / 2]

        # ìŠ¤í”¼ì»¤ë³„ ê¸°ëŒ€ ILD ë¶€í˜¸ (ì™¼ìª½ ìŠ¤í”¼ì»¤ëŠ” ì–‘ìˆ˜, ì˜¤ë¥¸ìª½ì€ ìŒìˆ˜)
        # ì–‘ìˆ˜: ì™¼ìª½ ê·€ê°€ ë” í° ì‹ í˜¸ë¥¼ ë°›ìŒ (ì •ìƒ)
        # ìŒìˆ˜: ì˜¤ë¥¸ìª½ ê·€ê°€ ë” í° ì‹ í˜¸ë¥¼ ë°›ìŒ (ì •ìƒ)
        # 0: ì¢Œìš° ëŒ€ì¹­ì— ê°€ê¹Œì›€
        self.expected_ild_sign = {
            # ê¸°ë³¸ ìŠ¤í”¼ì»¤
            'FL': +1.0, 'FC': 0.0, 'FR': -1.0,
            'SL': +1.0, 'SR': -1.0,
            'BL': +0.8, 'BC': 0.0, 'BR': -0.8,
            # ì²œì¥ ìŠ¤í”¼ì»¤ (ì¢Œìš° ëŒ€ì¹­ì— ê°€ê¹Œì›€)
            'TFL': +0.5, 'TFC': 0.0, 'TFR': -0.5,
            'TBL': +0.5, 'TBC': 0.0, 'TBR': -0.5,
            'TSL': +0.5, 'TSR': -0.5,
            # ì„œë¸Œìš°í¼ (ì¢Œìš° ë¬´ê´€)
            'LFE': 0.0, 'SW': 0.0,
        }

        # ê° ë°´ë“œë³„ ê²Œì´íŠ¸ ê¸¸ì´ ê³„ì‚°
        self._calculate_gate_lengths()

        # ìˆ˜ì§‘ëœ í¸ì°¨ ë°ì´í„° ì €ì¥
        self.all_speaker_deviations = {}
        self.mic_error_estimate = {}
        self.validation_result = {}

    def _calculate_gate_lengths(self):
        """ê° ì£¼íŒŒìˆ˜ ë°´ë“œë³„ ìµœì  ê²Œì´íŠ¸ ê¸¸ì´ ê³„ì‚°"""
        self.gate_lengths = {}

        for center_freq in self.octave_bands:
            # ì£¼íŒŒìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì§§ì€ ê²Œì´íŠ¸ ì‚¬ìš©
            if len(self.octave_bands) > 1:
                log_freq_ratio = np.log10(center_freq / self.octave_bands[0]) / \
                                np.log10(self.octave_bands[-1] / self.octave_bands[0])
            else:
                log_freq_ratio = 0.5
            cycles = self.max_gate_cycles - (self.max_gate_cycles - self.min_gate_cycles) * log_freq_ratio

            # ì‚¬ì´í´ ìˆ˜ë¥¼ ìƒ˜í”Œ ìˆ˜ë¡œ ë³€í™˜
            samples_per_cycle = self.fs / center_freq
            gate_samples = int(cycles * samples_per_cycle)

            # ìµœì†Œ 16ìƒ˜í”Œ, ìµœëŒ€ fs/10 ìƒ˜í”Œë¡œ ì œí•œ
            gate_samples = np.clip(gate_samples, 16, self.fs // 10)

            self.gate_lengths[center_freq] = gate_samples

    def _apply_frequency_gate(self, ir_data, center_freq, peak_index):
        """íŠ¹ì • ì£¼íŒŒìˆ˜ ë°´ë“œì— ëŒ€í•´ ì‹œê°„ ê²Œì´íŒ… ì ìš©"""
        gate_length = self.gate_lengths[center_freq]

        start_idx = peak_index
        end_idx = min(start_idx + gate_length, len(ir_data))

        if end_idx <= start_idx:
            return np.zeros(gate_length)

        gated_segment = ir_data[start_idx:end_idx]

        if len(gated_segment) < gate_length:
            gated_segment = np.pad(gated_segment, (0, gate_length - len(gated_segment)), 'constant')

        # í…Œì´í¼ ìœˆë„ìš° ì ìš©
        window = np.ones(gate_length)
        fade_length = min(gate_length // 4, 32)
        if fade_length > 0:
            window[-fade_length:] = np.linspace(1, 0, fade_length)

        return gated_segment * window

    def _measure_band_level(self, ir_data, center_freq, peak_index):
        """íŠ¹ì • ì£¼íŒŒìˆ˜ ë°´ë“œì˜ ë ˆë²¨(dB) ì¸¡ì •"""
        # ë°´ë“œíŒ¨ìŠ¤ í•„í„° ì„¤ê³„ (1/3 ì˜¥íƒ€ë¸Œ)
        lower_freq = center_freq / (2**(1/6))
        upper_freq = center_freq * (2**(1/6))
        upper_freq = min(upper_freq, self.fs / 2 * 0.95)

        if lower_freq >= upper_freq:
            return -100.0  # ìœ íš¨í•˜ì§€ ì•Šì€ ëŒ€ì—­

        try:
            sos = signal.butter(4, [lower_freq, upper_freq], btype='band', fs=self.fs, output='sos')
            filtered_ir = signal.sosfilt(sos, ir_data)
        except ValueError:
            filtered_ir = ir_data

        # ê²Œì´íŒ… ì ìš©
        gated_ir = self._apply_frequency_gate(filtered_ir, center_freq, peak_index)

        # FFTë¡œ ë ˆë²¨ ê³„ì‚°
        fft_length = max(len(gated_ir) * 2, 512)
        fft_result = fft(gated_ir, n=fft_length)
        freqs = fftfreq(fft_length, 1/self.fs)

        # ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ì— ê°€ì¥ ê°€ê¹Œìš´ ë¹ˆ ì°¾ê¸°
        center_bin = np.argmin(np.abs(freqs - center_freq))
        magnitude = np.abs(fft_result[center_bin])

        if magnitude > 0:
            return 20 * np.log10(magnitude)
        else:
            return -100.0

    def collect_speaker_deviation(self, speaker_name, left_ir, right_ir,
                                  left_peak_index=None, right_peak_index=None):
        """
        ë‹¨ì¼ ìŠ¤í”¼ì»¤ì˜ ì¢Œìš° í¸ì°¨ë¥¼ ìˆ˜ì§‘

        Args:
            speaker_name (str): ìŠ¤í”¼ì»¤ ì´ë¦„ (ì˜ˆ: 'FL', 'FR', 'FC')
            left_ir (np.array): ì¢Œì¸¡ ê·€ ì„í„ìŠ¤ ì‘ë‹µ
            right_ir (np.array): ìš°ì¸¡ ê·€ ì„í„ìŠ¤ ì‘ë‹µ
            left_peak_index (int): ì¢Œì¸¡ í”¼í¬ ì¸ë±ìŠ¤
            right_peak_index (int): ìš°ì¸¡ í”¼í¬ ì¸ë±ìŠ¤
        """
        if left_peak_index is None:
            left_peak_index = np.argmax(np.abs(left_ir))
        if right_peak_index is None:
            right_peak_index = np.argmax(np.abs(right_ir))

        speaker_deviations = {}

        for freq in self.octave_bands:
            left_level = self._measure_band_level(left_ir, freq, left_peak_index)
            right_level = self._measure_band_level(right_ir, freq, right_peak_index)

            # í¸ì°¨: ì–‘ìˆ˜ë©´ ì™¼ìª½ì´ ë” í¼
            deviation_db = left_level - right_level
            speaker_deviations[freq] = deviation_db

        self.all_speaker_deviations[speaker_name] = speaker_deviations
        return speaker_deviations

    def separate_microphone_error(self):
        """
        ë§ˆì´í¬ ì˜¤ì°¨ì™€ HRTF ë¹„ëŒ€ì¹­ì„ ë¶„ë¦¬

        ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì •: ê¸°ëŒ€ ILD ë¶€í˜¸ë¥¼ ê³ ë ¤í•œ ë¶„ì„
        - FLì—ì„œ +3dB, FRì—ì„œ +1dBê°€ ë‚˜ì™”ë‹¤ë©´,
          FLì€ ì›ë˜ ì–‘ìˆ˜ê°€ ê¸°ëŒ€ë˜ë¯€ë¡œ ì¼ë¶€ëŠ” HRTF
          FRì€ ì›ë˜ ìŒìˆ˜ê°€ ê¸°ëŒ€ë˜ë¯€ë¡œ +1dB ì „ì²´ê°€ ì´ìƒí•¨
        - ì´ëŸ° "ê¸°ëŒ€ì™€ ë°˜ëŒ€ ë°©í–¥" í¸ì°¨ë“¤ì˜ í‰ê· ì´ ë§ˆì´í¬ ì˜¤ì°¨

        Returns:
            dict: ì£¼íŒŒìˆ˜ë³„ ì¶”ì • ë§ˆì´í¬ ì˜¤ì°¨ (dB)
        """
        if not self.all_speaker_deviations:
            warnings.warn("ìˆ˜ì§‘ëœ ìŠ¤í”¼ì»¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € collect_speaker_deviationì„ í˜¸ì¶œí•˜ì„¸ìš”.")
            return {}

        mic_error_estimate = {}

        for freq in self.octave_bands:
            # ê¸°ëŒ€ ë°©í–¥ê³¼ ë°˜ëŒ€ë˜ëŠ” í¸ì°¨ë“¤ ìˆ˜ì§‘
            anomalous_deviations = []
            neutral_deviations = []  # ì¤‘ì•™ ìŠ¤í”¼ì»¤ í¸ì°¨

            for speaker, deviations in self.all_speaker_deviations.items():
                if freq not in deviations:
                    continue

                deviation = deviations[freq]
                expected_sign = self.expected_ild_sign.get(speaker, 0)

                if expected_sign > 0.5 and deviation < 0:
                    # ì™¼ìª½ ìŠ¤í”¼ì»¤ì¸ë° ì˜¤ë¥¸ìª½ì´ ë” í¼ -> ì´ìƒ
                    anomalous_deviations.append(deviation)
                elif expected_sign < -0.5 and deviation > 0:
                    # ì˜¤ë¥¸ìª½ ìŠ¤í”¼ì»¤ì¸ë° ì™¼ìª½ì´ ë” í¼ -> ì´ìƒ
                    anomalous_deviations.append(deviation)
                elif abs(expected_sign) <= 0.5:
                    # ì¤‘ì•™/ì²œì¥ ìŠ¤í”¼ì»¤ëŠ” ì›ë˜ 0ì— ê°€ê¹Œì›Œì•¼ í•¨
                    neutral_deviations.append(deviation)

            # ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì •
            if anomalous_deviations:
                # ì´ìƒ í¸ì°¨ë“¤ì˜ ì¤‘ì•™ê°’ = ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì •
                mic_error_estimate[freq] = np.median(anomalous_deviations)
            elif neutral_deviations:
                # ì¤‘ì•™ ìŠ¤í”¼ì»¤ í¸ì°¨ì˜ ì¤‘ì•™ê°’ ì‚¬ìš©
                mic_error_estimate[freq] = np.median(neutral_deviations)
            else:
                # ëª¨ë“  í¸ì°¨ê°€ ê¸°ëŒ€ ë°©í–¥ì´ë©´ ì „ì²´ ì¤‘ì•™ê°’ì˜ ì¼ë¶€ë¥¼ ë§ˆì´í¬ ì˜¤ì°¨ë¡œ ì¶”ì •
                all_devs = [d[freq] for d in self.all_speaker_deviations.values() if freq in d]
                if all_devs:
                    # ì „ì²´ ì¤‘ì•™ê°’ì˜ 30%ë§Œ ë§ˆì´í¬ ì˜¤ì°¨ë¡œ ê°„ì£¼ (ë³´ìˆ˜ì  ì¶”ì •)
                    mic_error_estimate[freq] = np.median(all_devs) * 0.3
                else:
                    mic_error_estimate[freq] = 0.0

        self.mic_error_estimate = mic_error_estimate
        return mic_error_estimate

    def validate_consistency(self):
        """
        ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨ì˜ ì¼ê´€ì„± ê²€ì¦

        ë§ˆì´í¬ ì˜¤ì°¨ë¥¼ ë¹¼ê³  ë‚˜ë©´ ë‚¨ì€ í¸ì°¨ê°€ ë¬¼ë¦¬ì ìœ¼ë¡œ íƒ€ë‹¹í•´ì•¼ í•¨:
        - FL, SL, BLì—ì„œëŠ” ì–‘ìˆ˜ (ì™¼ìª½ ê·€ê°€ ê°€ê¹Œì›€)
        - FR, SR, BRì—ì„œëŠ” ìŒìˆ˜ (ì˜¤ë¥¸ìª½ ê·€ê°€ ê°€ê¹Œì›€)
        - FCì—ì„œëŠ” 0ì— ê°€ê¹Œì›€

        Returns:
            dict: ê²€ì¦ ê²°ê³¼
        """
        if not self.mic_error_estimate or not self.all_speaker_deviations:
            return {'valid': False, 'reason': 'ë°ì´í„° ë¶€ì¡±'}

        validation_scores = []
        details = []

        for freq in self.octave_bands:
            if freq not in self.mic_error_estimate:
                continue

            mic_error = self.mic_error_estimate[freq]

            for speaker, deviations in self.all_speaker_deviations.items():
                if freq not in deviations:
                    continue

                raw_deviation = deviations[freq]
                corrected_deviation = raw_deviation - mic_error
                expected_sign = self.expected_ild_sign.get(speaker, 0)

                # ë³´ì • í›„ í¸ì°¨ê°€ ê¸°ëŒ€ ë°©í–¥ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if abs(expected_sign) > 0.3:
                    # ë¶€í˜¸ ì¼ì¹˜: +1, ë¶ˆì¼ì¹˜: -1
                    if corrected_deviation * expected_sign > 0:
                        sign_match = 1.0
                    elif abs(corrected_deviation) < 1.0:  # 1dB ë¯¸ë§Œì€ ì¤‘ë¦½
                        sign_match = 0.5
                    else:
                        sign_match = 0.0

                    validation_scores.append(sign_match)
                    details.append({
                        'speaker': speaker,
                        'freq': freq,
                        'raw': raw_deviation,
                        'corrected': corrected_deviation,
                        'expected_sign': expected_sign,
                        'match': sign_match
                    })

        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        if validation_scores:
            consistency = np.mean(validation_scores)
        else:
            consistency = 0.5  # ë°ì´í„° ë¶€ì¡± ì‹œ ì¤‘ë¦½

        self.validation_result = {
            'consistency_score': consistency,
            'is_valid': consistency > 0.4,  # 40% ì´ìƒ ì¼ì¹˜í•˜ë©´ ìœ íš¨
            'confidence': 'high' if consistency > 0.7 else 'medium' if consistency > 0.5 else 'low',
            'details': details
        }

        return self.validation_result

    def design_correction_filters(self):
        """
        ë§ˆì´í¬ ì˜¤ì°¨ ë³´ì • í•„í„° ì„¤ê³„

        í¬ê¸° ë³´ì •ë§Œ ìˆ˜í–‰, ìœ„ìƒì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        (ìœ„ìƒ ë³´ì • + minimum_phase ëª¨ìˆœ íšŒí”¼)

        Returns:
            tuple: (left_fir, right_fir) ë³´ì • í•„í„°ë“¤
        """
        if not self.mic_error_estimate:
            warnings.warn("ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¨¼ì € separate_microphone_errorë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.")
            return np.array([1.0]), np.array([1.0])

        frequencies = FrequencyResponse.generate_frequencies(
            f_step=1.01, f_min=20, f_max=self.fs/2
        )

        # ì˜¥íƒ€ë¸Œ ë°´ë“œì˜ ë§ˆì´í¬ ì˜¤ì°¨ë¥¼ ì—°ì† ê³¡ì„ ìœ¼ë¡œ ë³´ê°„
        band_freqs = np.array(sorted(self.mic_error_estimate.keys()))
        band_errors = np.array([self.mic_error_estimate[f] for f in band_freqs])

        if len(band_freqs) < 2:
            # ë°ì´í„° ë¶€ì¡± ì‹œ ë‹¨ì¼ ê°’ìœ¼ë¡œ ë³´ì •
            correction_curve = np.full(len(frequencies), band_errors[0] if len(band_errors) > 0 else 0.0)
        else:
            # ë¡œê·¸ ì£¼íŒŒìˆ˜ ê³µê°„ì—ì„œ ì„ í˜• ë³´ê°„
            interpolator = interp1d(
                np.log10(band_freqs),
                band_errors,
                kind='linear',
                bounds_error=False,
                fill_value=(band_errors[0], band_errors[-1])
            )
            correction_curve = interpolator(np.log10(frequencies))

        # ë³´ì • ê°•ë„ ì ìš©
        correction_curve *= self.correction_strength

        # ìµœëŒ€ ë³´ì •ëŸ‰ ì œí•œ
        correction_curve = np.clip(correction_curve, -self.max_correction_db, self.max_correction_db)

        # FrequencyResponse ê°ì²´ë¡œ FIR ìƒì„±
        # ì™¼ìª½ì—ëŠ” -correction/2, ì˜¤ë¥¸ìª½ì—ëŠ” +correction/2 ì ìš©
        # (ì´ correctionë§Œí¼ ìƒëŒ€ì  ì°¨ì´ ë³´ì •)
        left_fr = FrequencyResponse(
            name='left_mic_correction',
            frequency=frequencies.copy(),
            raw=-correction_curve / 2
        )
        right_fr = FrequencyResponse(
            name='right_mic_correction',
            frequency=frequencies.copy(),
            raw=correction_curve / 2
        )

        # ìµœì†Œ ìœ„ìƒ FIR ìƒì„± (í¬ê¸°ë§Œ ë³´ì •í•˜ë¯€ë¡œ minimum_phase ì‚¬ìš©ì´ ì ì ˆí•¨)
        try:
            left_fir = left_fr.minimum_phase_impulse_response(fs=self.fs, normalize=False)
            right_fir = right_fr.minimum_phase_impulse_response(fs=self.fs, normalize=False)

            # FIR ê¸¸ì´ ì œí•œ
            max_fir_length = min(1024, self.fs // 10)
            if len(left_fir) > max_fir_length:
                left_fir = left_fir[:max_fir_length]
            if len(right_fir) > max_fir_length:
                right_fir = right_fir[:max_fir_length]

        except Exception as e:
            warnings.warn(f"FIR í•„í„° ìƒì„± ì‹¤íŒ¨: {e}. ë‹¨ìœ„ ì„í„ìŠ¤ ë°˜í™˜.")
            left_fir = np.array([1.0])
            right_fir = np.array([1.0])

        return left_fir, right_fir

    def get_analysis_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë°˜í™˜"""
        if not self.mic_error_estimate:
            return {'error': 'ë¶„ì„ ë¯¸ì™„ë£Œ'}

        # í‰ê· /ìµœëŒ€ ë§ˆì´í¬ ì˜¤ì°¨
        errors = list(self.mic_error_estimate.values())
        avg_error = np.mean(np.abs(errors)) if errors else 0.0
        max_error = np.max(np.abs(errors)) if errors else 0.0

        return {
            'mic_error_estimate': self.mic_error_estimate.copy(),
            'avg_error_db': avg_error,
            'max_error_db': max_error,
            'speakers_analyzed': list(self.all_speaker_deviations.keys()),
            'validation': self.validation_result.copy() if self.validation_result else {},
            'correction_strength': self.correction_strength
        }


# ê¸°ì¡´ API í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤
class MicrophoneDeviationCorrector(CrossValidatedMicrophoneCorrector):
    """
    ê¸°ì¡´ API í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤

    v2.0 APIë¥¼ v3.0 êµì°¨ê²€ì¦ ê¸°ë°˜ êµ¬í˜„ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
    enable_phase_correction, enable_adaptive_correction ë“±ì˜ íŒŒë¼ë¯¸í„°ëŠ”
    ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë©° ë¬´ì‹œë©ë‹ˆë‹¤.
    """

    def __init__(self, sample_rate,
                 octave_bands=None,
                 min_gate_cycles=2,
                 max_gate_cycles=8,
                 correction_strength=0.7,
                 smoothing_window=1/3,
                 max_correction_db=6.0,
                 enable_phase_correction=True,  # ë¬´ì‹œë¨ (v3.0ì—ì„œ ì œê±°)
                 enable_adaptive_correction=True,  # ë¬´ì‹œë¨ (v3.0ì—ì„œ ì œê±°)
                 enable_anatomical_validation=True,  # ë¬´ì‹œë¨ (v3.0ì—ì„œ í†µí•©)
                 itd_range_ms=(-0.7, 0.7),  # ë¬´ì‹œë¨
                 head_radius_cm=8.75):  # ë¬´ì‹œë¨
        """
        Args:
            sample_rate (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
            octave_bands (list): ë¶„ì„í•  ì˜¥íƒ€ë¸Œ ë°´ë“œ ì¤‘ì‹¬ ì£¼íŒŒìˆ˜ë“¤ (Hz)
            min_gate_cycles (float): ìµœì†Œ ê²Œì´íŠ¸ ê¸¸ì´ (ì‚¬ì´í´ ìˆ˜)
            max_gate_cycles (float): ìµœëŒ€ ê²Œì´íŠ¸ ê¸¸ì´ (ì‚¬ì´í´ ìˆ˜)
            correction_strength (float): ë³´ì • ê°•ë„ (0.0~1.0)
            smoothing_window (float): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (v3.0ì—ì„œ ì œê±°)
            max_correction_db (float): ìµœëŒ€ ë³´ì •ëŸ‰ (dB)
            enable_phase_correction (bool): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (v3.0ì—ì„œ ì œê±°ë¨)
            enable_adaptive_correction (bool): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (v3.0ì—ì„œ ì œê±°ë¨)
            enable_anatomical_validation (bool): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (v3.0ì—ì„œ í†µí•©)
            itd_range_ms (tuple): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
            head_radius_cm (float): ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
        """
        # v3.0 ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(
            sample_rate=sample_rate,
            correction_strength=correction_strength,
            octave_bands=octave_bands,
            max_correction_db=max_correction_db,
            min_gate_cycles=min_gate_cycles,
            max_gate_cycles=max_gate_cycles
        )

        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ê²½ê³ 
        if enable_phase_correction:
            warnings.warn(
                "enable_phase_correctionì€ v3.0ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. "
                "ìœ„ìƒ ë³´ì •ì€ minimum_phaseì™€ êµ¬ì¡°ì ìœ¼ë¡œ ëª¨ìˆœë˜ì–´ "
                "í¬ê¸° ë³´ì •ë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.",
                DeprecationWarning
            )

    def correct_microphone_deviation(self, left_ir, right_ir,
                                     left_peak_index=None, right_peak_index=None,
                                     plot_analysis=False, plot_dir=None):
        """
        ë‹¨ì¼ ìŠ¤í”¼ì»¤ì— ëŒ€í•œ ë§ˆì´í¬ ì°©ìš© í¸ì°¨ ë³´ì • (ê¸°ì¡´ API í˜¸í™˜)

        ì£¼ì˜: ì´ ë©”ì„œë“œëŠ” ë‹¨ì¼ ìŠ¤í”¼ì»¤ë§Œ ë¶„ì„í•˜ë¯€ë¡œ êµì°¨ê²€ì¦ì´ ì œí•œë©ë‹ˆë‹¤.
        ë” ì •í™•í•œ ë³´ì •ì„ ìœ„í•´ì„œëŠ” apply_microphone_deviation_correction_to_hrirë¥¼
        ì‚¬ìš©í•˜ì„¸ìš”.
        """
        # ì…ë ¥ ê²€ì¦
        if len(left_ir) != len(right_ir):
            min_len = min(len(left_ir), len(right_ir))
            left_ir = left_ir[:min_len]
            right_ir = right_ir[:min_len]

        if left_peak_index is None:
            left_peak_index = np.argmax(np.abs(left_ir))
        if right_peak_index is None:
            right_peak_index = np.argmax(np.abs(right_ir))

        # ë‹¨ì¼ ìŠ¤í”¼ì»¤ ë°ì´í„° ìˆ˜ì§‘ (êµì°¨ê²€ì¦ ì—†ì´)
        self.collect_speaker_deviation('SINGLE', left_ir, right_ir,
                                       left_peak_index, right_peak_index)

        # ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì • (ë‹¨ì¼ ìŠ¤í”¼ì»¤ì˜ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        # êµì°¨ê²€ì¦ ì—†ì´ ë‹¨ìˆœ í¸ì°¨ë¥¼ ë§ˆì´í¬ ì˜¤ì°¨ë¡œ ê°„ì£¼
        self.mic_error_estimate = self.all_speaker_deviations.get('SINGLE', {})

        # ìœ ì˜ë¯¸í•œ í¸ì°¨ í™•ì¸
        significant_deviations = [abs(d) for d in self.mic_error_estimate.values() if abs(d) > 0.5]

        if not significant_deviations:
            print("ìœ ì˜ë¯¸í•œ ë§ˆì´í¬ í¸ì°¨ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë³´ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            analysis_results = {
                'deviation_results': {'frequency_deviations': self.mic_error_estimate},
                'correction_filters': {'left_fir': np.array([1.0]), 'right_fir': np.array([1.0])},
                'correction_applied': False,
                'v3_cross_validation': False
            }
            return left_ir.copy(), right_ir.copy(), analysis_results

        # ë³´ì • í•„í„° ìƒì„±
        left_fir, right_fir = self.design_correction_filters()

        # ë³´ì • ì ìš©
        try:
            if len(left_fir) > 1 and len(right_fir) > 1:
                corrected_left = signal.convolve(left_ir, left_fir, mode='same')
                corrected_right = signal.convolve(right_ir, right_fir, mode='same')
            else:
                corrected_left = left_ir.copy()
                corrected_right = right_ir.copy()
        except Exception as e:
            print(f"ë³´ì • í•„í„° ì ìš© ì‹¤íŒ¨: {e}. ì›ë³¸ ë°˜í™˜.")
            corrected_left = left_ir.copy()
            corrected_right = right_ir.copy()

        analysis_results = {
            'deviation_results': {'frequency_deviations': self.mic_error_estimate},
            'correction_filters': {'left_fir': left_fir, 'right_fir': right_fir},
            'correction_applied': True,
            'avg_deviation_db': np.mean(significant_deviations),
            'max_deviation_db': np.max(significant_deviations),
            'v3_cross_validation': False
        }

        if plot_analysis and plot_dir:
            self._plot_analysis_results(left_ir, right_ir, corrected_left, corrected_right,
                                        analysis_results, plot_dir)

        return corrected_left, corrected_right, analysis_results

    def _plot_analysis_results(self, original_left, original_right,
                               corrected_left, corrected_right,
                               analysis_results, plot_dir):
        """ë¶„ì„ ê²°ê³¼ í”Œë¡¯ ìƒì„±"""
        os.makedirs(plot_dir, exist_ok=True)

        # 1. í¸ì°¨ ë¶„ì„ ê²°ê³¼ í”Œë¡¯
        fig, ax = plt.subplots(figsize=(12, 6))

        deviations = analysis_results['deviation_results']['frequency_deviations']
        freqs = sorted(deviations.keys())
        values = [deviations[f] for f in freqs]

        ax.semilogx(freqs, values, 'o-', linewidth=2, markersize=8, label='ì¸¡ì •ëœ í¸ì°¨ (L-R)')
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        ax.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)', fontsize=11)
        ax.set_ylabel('í¸ì°¨ (dB)', fontsize=11)
        ax.set_title('ë§ˆì´í¬ ì°©ìš© í¸ì°¨ ë¶„ì„ (v3.0 - í¬ê¸°ë§Œ ë³´ì •)', fontsize=13)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=10)

        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, 'microphone_deviation_analysis_v3.png'),
                    dpi=150, bbox_inches='tight')
        plt.close()

        # 2. ë³´ì • ì „í›„ ë¹„êµ í”Œë¡¯
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))

        fft_len = max(len(original_left) * 2, 8192)
        freqs_fft = np.fft.fftfreq(fft_len, 1/self.fs)[:fft_len//2]

        orig_left_fft = np.fft.fft(original_left, n=fft_len)[:fft_len//2]
        orig_right_fft = np.fft.fft(original_right, n=fft_len)[:fft_len//2]
        corr_left_fft = np.fft.fft(corrected_left, n=fft_len)[:fft_len//2]
        corr_right_fft = np.fft.fft(corrected_right, n=fft_len)[:fft_len//2]

        orig_left_db = 20 * np.log10(np.abs(orig_left_fft) + 1e-12)
        orig_right_db = 20 * np.log10(np.abs(orig_right_fft) + 1e-12)
        corr_left_db = 20 * np.log10(np.abs(corr_left_fft) + 1e-12)
        corr_right_db = 20 * np.log10(np.abs(corr_right_fft) + 1e-12)

        ax1.semilogx(freqs_fft, orig_left_db, alpha=0.6, label='ì›ë³¸ ì¢Œì¸¡', color='blue')
        ax1.semilogx(freqs_fft, orig_right_db, alpha=0.6, label='ì›ë³¸ ìš°ì¸¡', color='red')
        ax1.semilogx(freqs_fft, corr_left_db, '--', label='ë³´ì • ì¢Œì¸¡', color='darkblue')
        ax1.semilogx(freqs_fft, corr_right_db, '--', label='ë³´ì • ìš°ì¸¡', color='darkred')
        ax1.set_ylabel('í¬ê¸° (dB)', fontsize=11)
        ax1.set_title('ë§ˆì´í¬ í¸ì°¨ ë³´ì • ì „í›„ ë¹„êµ (v3.0)', fontsize=13)
        ax1.set_xlim([20, self.fs/2])
        ax1.grid(True, alpha=0.3)
        ax1.legend(fontsize=10)

        orig_diff = orig_left_db - orig_right_db
        corr_diff = corr_left_db - corr_right_db

        ax2.semilogx(freqs_fft, orig_diff, alpha=0.7, label='ì›ë³¸ L-R ì°¨ì´', color='purple')
        ax2.semilogx(freqs_fft, corr_diff, '--', label='ë³´ì • í›„ L-R ì°¨ì´', color='green')
        ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        ax2.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)', fontsize=11)
        ax2.set_ylabel('ì¢Œìš° ì°¨ì´ (dB)', fontsize=11)
        ax2.set_xlim([20, self.fs/2])
        ax2.grid(True, alpha=0.3)
        ax2.legend(fontsize=10)

        plt.tight_layout()
        plt.savefig(os.path.join(plot_dir, 'microphone_deviation_correction_comparison_v2.png'),
                    dpi=150, bbox_inches='tight')
        plt.close()

        print(f"âœ… ë§ˆì´í¬ í¸ì°¨ ë³´ì • ë¶„ì„ í”Œë¡¯ì´ {plot_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def apply_microphone_deviation_correction_to_hrir(hrir,
                                                  correction_strength=0.7,
                                                  enable_phase_correction=True,  # ë¬´ì‹œë¨
                                                  enable_adaptive_correction=True,  # ë¬´ì‹œë¨
                                                  enable_anatomical_validation=True,  # ë¬´ì‹œë¨
                                                  plot_analysis=False,
                                                  plot_dir=None):
    """
    HRIR ê°ì²´ì— êµì°¨ê²€ì¦ ê¸°ë°˜ ë§ˆì´í¬ ì°©ìš© í¸ì°¨ ë³´ì • ì ìš© (v3.0)

    ì´ í•¨ìˆ˜ëŠ” ëª¨ë“  ìŠ¤í”¼ì»¤ì˜ ë°ì´í„°ë¥¼ ë¨¼ì € ìˆ˜ì§‘í•œ í›„,
    êµì°¨ê²€ì¦ì„ í†µí•´ ë§ˆì´í¬ ì˜¤ì°¨ì™€ HRTF ë¹„ëŒ€ì¹­ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.

    Args:
        hrir (HRIR): HRIR ê°ì²´
        correction_strength (float): ë³´ì • ê°•ë„ (0.0~1.0)
        enable_phase_correction (bool): ë¬´ì‹œë¨ (v3.0ì—ì„œ ì œê±°)
        enable_adaptive_correction (bool): ë¬´ì‹œë¨ (v3.0ì—ì„œ ì œê±°)
        enable_anatomical_validation (bool): ë¬´ì‹œë¨ (v3.0ì—ì„œ í†µí•©)
        plot_analysis (bool): ë¶„ì„ ê²°ê³¼ í”Œë¡¯ ìƒì„± ì—¬ë¶€
        plot_dir (str): í”Œë¡¯ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    corrector = CrossValidatedMicrophoneCorrector(
        sample_rate=hrir.fs,
        correction_strength=correction_strength
    )

    print("\nğŸ§ ë§ˆì´í¬ í¸ì°¨ ë³´ì • v3.0 ì‹œì‘ (êµì°¨ê²€ì¦ ê¸°ë°˜)")
    print(f"  - ë³´ì • ê°•ë„: {correction_strength}")
    print(f"  - ë¶„ì„ ëŒ€ìƒ ìŠ¤í”¼ì»¤: {len(hrir.irs)}ê°œ")
    print()

    # 1ë‹¨ê³„: ëª¨ë“  ìŠ¤í”¼ì»¤ì—ì„œ ì¢Œìš° í¸ì°¨ ìˆ˜ì§‘
    print("ğŸ“Š 1ë‹¨ê³„: ëª¨ë“  ìŠ¤í”¼ì»¤ì—ì„œ í¸ì°¨ ìˆ˜ì§‘ ì¤‘...")

    speaker_data = {}  # IR ë°ì´í„° ì €ì¥ (ë‚˜ì¤‘ì— ë³´ì • ì ìš©ìš©)

    for speaker, pair in hrir.irs.items():
        left_ir = pair['left']
        right_ir = pair['right']

        left_peak = left_ir.peak_index()
        right_peak = right_ir.peak_index()

        if left_peak is None or right_peak is None:
            print(f"  âš ï¸ {speaker}: í”¼í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # í¸ì°¨ ìˆ˜ì§‘
        corrector.collect_speaker_deviation(
            speaker, left_ir.data, right_ir.data, left_peak, right_peak
        )

        # IR ë°ì´í„° ì €ì¥
        speaker_data[speaker] = {
            'left_ir': left_ir,
            'right_ir': right_ir,
            'left_peak': left_peak,
            'right_peak': right_peak
        }

        print(f"  âœ“ {speaker}: í¸ì°¨ ìˆ˜ì§‘ ì™„ë£Œ")

    if len(corrector.all_speaker_deviations) < 2:
        print("\nâš ï¸ êµì°¨ê²€ì¦ì— ì¶©ë¶„í•œ ìŠ¤í”¼ì»¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ìµœì†Œ 2ê°œ í•„ìš”).")
        print("   ë‹¨ì¼ ìŠ¤í”¼ì»¤ ë³´ì • ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        # ë‹¨ì¼ ìŠ¤í”¼ì»¤ ëª¨ë“œë¡œ í´ë°±
        return _apply_single_speaker_fallback(hrir, corrector, speaker_data, plot_analysis, plot_dir)

    # 2ë‹¨ê³„: ë§ˆì´í¬ ì˜¤ì°¨ì™€ HRTF ë¹„ëŒ€ì¹­ ë¶„ë¦¬
    print("\nğŸ“Š 2ë‹¨ê³„: êµì°¨ê²€ì¦ìœ¼ë¡œ ë§ˆì´í¬ ì˜¤ì°¨ ë¶„ë¦¬ ì¤‘...")
    mic_error = corrector.separate_microphone_error()

    if not mic_error:
        print("  âš ï¸ ë§ˆì´í¬ ì˜¤ì°¨ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {'error': 'ë§ˆì´í¬ ì˜¤ì°¨ ì¶”ì • ì‹¤íŒ¨'}

    # ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨ ì¶œë ¥
    print("\n  ğŸ“ˆ ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨ (ì–‘ìˆ˜ = ì™¼ìª½ì´ ë” í¼):")
    for freq in sorted(mic_error.keys()):
        print(f"     {freq:5d} Hz: {mic_error[freq]:+.2f} dB")

    # 3ë‹¨ê³„: ì¼ê´€ì„± ê²€ì¦
    print("\nğŸ“Š 3ë‹¨ê³„: ì¼ê´€ì„± ê²€ì¦ ì¤‘...")
    validation = corrector.validate_consistency()

    print(f"  ì¼ê´€ì„± ì ìˆ˜: {validation['consistency_score']:.2f}")
    print(f"  ì‹ ë¢°ë„: {validation['confidence']}")

    if not validation['is_valid']:
        print("  âš ï¸ ì¼ê´€ì„± ê²€ì¦ ì‹¤íŒ¨. ë³´ì •ì„ ì•½í•˜ê²Œ ì ìš©í•©ë‹ˆë‹¤.")
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ë³´ì • ê°•ë„ë¥¼ ì¤„ì„
        corrector.correction_strength *= 0.5

    # 4ë‹¨ê³„: ë³´ì • í•„í„° ìƒì„± ë° ì ìš©
    print("\nğŸ“Š 4ë‹¨ê³„: ë³´ì • í•„í„° ìƒì„± ë° ì ìš© ì¤‘...")
    left_fir, right_fir = corrector.design_correction_filters()

    # ê° ìŠ¤í”¼ì»¤ì— ë³´ì • ì ìš©
    for speaker, data in speaker_data.items():
        try:
            if len(left_fir) > 1 and len(right_fir) > 1:
                corrected_left = signal.convolve(data['left_ir'].data, left_fir, mode='same')
                corrected_right = signal.convolve(data['right_ir'].data, right_fir, mode='same')

                data['left_ir'].data = corrected_left
                data['right_ir'].data = corrected_right

                print(f"  âœ“ {speaker}: ë³´ì • ì ìš© ì™„ë£Œ")
            else:
                print(f"  â„¹ï¸ {speaker}: ë³´ì • í•„í„° ì—†ìŒ, ì›ë³¸ ìœ ì§€")
        except Exception as e:
            print(f"  âš ï¸ {speaker}: ë³´ì • ì ìš© ì‹¤íŒ¨ ({e})")

    # í”Œë¡¯ ìƒì„±
    if plot_analysis and plot_dir:
        _plot_cross_validation_results(corrector, plot_dir)

    # ë¶„ì„ ê²°ê³¼ ë°˜í™˜
    summary = corrector.get_analysis_summary()
    summary['v3_cross_validation'] = True
    summary['speakers_processed'] = list(speaker_data.keys())

    print(f"\nâœ… ë§ˆì´í¬ í¸ì°¨ ë³´ì • v3.0 ì™„ë£Œ")
    print(f"   í‰ê·  ë³´ì •ëŸ‰: {summary['avg_error_db']:.2f} dB")
    print(f"   ìµœëŒ€ ë³´ì •ëŸ‰: {summary['max_error_db']:.2f} dB")

    return summary


def _apply_single_speaker_fallback(hrir, corrector, speaker_data, plot_analysis, plot_dir):
    """ë‹¨ì¼ ìŠ¤í”¼ì»¤ ë°ì´í„°ë§Œ ìˆì„ ë•Œ í´ë°± ì²˜ë¦¬"""
    print("   (ë‹¨ì¼ ìŠ¤í”¼ì»¤ ëª¨ë“œ: êµì°¨ê²€ì¦ ì—†ì´ ì§ì ‘ ë³´ì •)")

    # ìˆ˜ì§‘ëœ í¸ì°¨ë¥¼ ê·¸ëŒ€ë¡œ ë§ˆì´í¬ ì˜¤ì°¨ë¡œ ê°„ì£¼
    if corrector.all_speaker_deviations:
        speaker_name = list(corrector.all_speaker_deviations.keys())[0]
        corrector.mic_error_estimate = corrector.all_speaker_deviations[speaker_name]

    # ë³´ì • ì ìš©
    left_fir, right_fir = corrector.design_correction_filters()

    for speaker, data in speaker_data.items():
        try:
            if len(left_fir) > 1:
                data['left_ir'].data = signal.convolve(data['left_ir'].data, left_fir, mode='same')
                data['right_ir'].data = signal.convolve(data['right_ir'].data, right_fir, mode='same')
        except Exception as e:
            print(f"  âš ï¸ {speaker}: ë³´ì • ì ìš© ì‹¤íŒ¨ ({e})")

    return {
        'v3_cross_validation': False,
        'single_speaker_fallback': True,
        'mic_error_estimate': corrector.mic_error_estimate
    }


def _plot_cross_validation_results(corrector, plot_dir):
    """êµì°¨ê²€ì¦ ê²°ê³¼ í”Œë¡¯ ìƒì„±"""
    os.makedirs(plot_dir, exist_ok=True)

    fig, axes = plt.subplots(2, 1, figsize=(14, 10))

    # 1. ìŠ¤í”¼ì»¤ë³„ í¸ì°¨ ë¹„êµ
    ax1 = axes[0]

    speakers = list(corrector.all_speaker_deviations.keys())
    freqs = sorted(corrector.octave_bands)

    for speaker in speakers:
        deviations = corrector.all_speaker_deviations[speaker]
        values = [deviations.get(f, 0) for f in freqs]
        expected_sign = corrector.expected_ild_sign.get(speaker, 0)

        linestyle = '-' if expected_sign >= 0 else '--'
        ax1.semilogx(freqs, values, linestyle, marker='o', label=f'{speaker} (ê¸°ëŒ€ë¶€í˜¸: {expected_sign:+.1f})')

    ax1.axhline(y=0, color='gray', linestyle=':', alpha=0.5)
    ax1.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)', fontsize=11)
    ax1.set_ylabel('í¸ì°¨ (dB) [ì–‘ìˆ˜=ì™¼ìª½>ì˜¤ë¥¸ìª½]', fontsize=11)
    ax1.set_title('ìŠ¤í”¼ì»¤ë³„ ì¢Œìš° í¸ì°¨ (êµì°¨ê²€ì¦ v3.0)', fontsize=13)
    ax1.legend(fontsize=9, loc='best', ncol=2)
    ax1.grid(True, alpha=0.3)

    # 2. ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨
    ax2 = axes[1]

    mic_error = corrector.mic_error_estimate
    mic_freqs = sorted(mic_error.keys())
    mic_values = [mic_error[f] for f in mic_freqs]

    ax2.semilogx(mic_freqs, mic_values, 'k-', marker='s', linewidth=2,
                 markersize=10, label='ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨')
    ax2.axhline(y=0, color='gray', linestyle=':', alpha=0.5)

    # ë³´ì • í›„ ì˜ˆìƒ í¸ì°¨ (ê° ìŠ¤í”¼ì»¤ì— ëŒ€í•´)
    for speaker in speakers:
        deviations = corrector.all_speaker_deviations[speaker]
        corrected = [deviations.get(f, 0) - mic_error.get(f, 0) for f in mic_freqs]
        ax2.semilogx(mic_freqs, corrected, '--', alpha=0.5, label=f'{speaker} ë³´ì • í›„ ì˜ˆìƒ')

    ax2.set_xlabel('ì£¼íŒŒìˆ˜ (Hz)', fontsize=11)
    ax2.set_ylabel('í¸ì°¨ (dB)', fontsize=11)
    ax2.set_title('ì¶”ì •ëœ ë§ˆì´í¬ ì˜¤ì°¨ ë° ë³´ì • í›„ ì˜ˆìƒ í¸ì°¨', fontsize=13)
    ax2.legend(fontsize=9, loc='best', ncol=2)
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, 'microphone_deviation_cross_validation_v3.png'),
                dpi=150, bbox_inches='tight')
    plt.close()

    print(f"âœ… êµì°¨ê²€ì¦ ë¶„ì„ í”Œë¡¯ì´ {plot_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
