# -*- coding: utf-8 -*-

import os
import re
import argparse
from tabulate import tabulate
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from autoeq.frequency_response import FrequencyResponse
from impulse_response_estimator import ImpulseResponseEstimator
from hrir import HRIR
from room_correction import room_correction
from utils import (
    sync_axes,
    save_fig_as_png,
    is_truehd_file,
    convert_truehd_to_wav,
    check_ffmpeg_available,
)
from constants import (
    SPEAKER_NAMES,
    SPEAKER_LIST_PATTERN,
    HESUVI_TRACK_ORDER,
    TEST_SIGNALS,
    get_data_path,
    TRUEHD_11CH_ORDER,
    TRUEHD_13CH_ORDER,
)
from channel_generation import (
    get_available_channels_for_layout,
    create_truehd_layout_track_order,
    validate_channel_requirements,
)
from logger import get_logger

# PR3ì—ì„œ ì¶”ê°€ëœ import ë¬¸ë“¤
import copy
import contextlib
import io
from scipy.interpolate import interp1d  # íë¹… ë³´ê°„ì„ ìœ„í•´ ì¶”ê°€

# Bokeh Tabs/Panel import ì¶”ê°€
# from bokeh.models import Panel, Tabs # ì´ì „ ì‹œë„
from bokeh.models import TabPanel, Tabs  # ìˆ˜ì •: Panel -> TabPanel
from bokeh.plotting import (
    output_file as bokeh_output_file,
    save as bokeh_save,
)  # ì¤‘ë³µ ë°©ì§€

# í•œê¸€ í°íŠ¸ ì„¤ì • ì¶”ê°€
import matplotlib.font_manager as fm
import platform
import importlib.resources  # íŒ¨í‚¤ì§€ ë¦¬ì†ŒìŠ¤ ì ‘ê·¼ì„ ìœ„í•´ ì¶”ê°€

# Python 3.14 ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
try:
    from parallel_processing import parallel_process_dict, is_free_threaded_available

    PARALLEL_PROCESSING_AVAILABLE = True
except ImportError:
    PARALLEL_PROCESSING_AVAILABLE = False
    parallel_process_dict = None

    def is_free_threaded_available():
        return False


# ìš´ì˜ì²´ì œë³„ ê¸°ë³¸ í°íŠ¸ ì„¤ì •
def set_matplotlib_font():
    system = platform.system()
    font_name_pretendard = "Pretendard"
    font_loaded_pretendard = False

    plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ë¬¸ì œ í•´ê²°

    # Pretendard í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„
    font_search_paths = []

    try:
        # 1. íŒ¨í‚¤ì§€ ë‚´ í°íŠ¸ ì‹œë„
        try:
            # Python 3.9+ ì—ì„œëŠ” files() ì‚¬ìš©
            if hasattr(importlib.resources, "files"):
                try:
                    # ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ì—ì„œ ì‹œë„
                    font_resource = (
                        importlib.resources.files("impulcifer_py313")
                        .joinpath("font")
                        .joinpath("Pretendard-Regular.otf")
                    )
                    font_search_paths.append(("bundled (files)", font_resource))
                except (FileNotFoundError, ModuleNotFoundError):
                    pass

            # Python 3.7, 3.8 í˜¸í™˜ (path ì‚¬ìš©)
            elif hasattr(importlib.resources, "path"):
                try:
                    font_resource = importlib.resources.path(
                        "impulcifer_py313.font", "Pretendard-Regular.otf"
                    )
                    font_search_paths.append(("bundled (path)", font_resource))
                except (FileNotFoundError, ModuleNotFoundError):
                    pass
        except ImportError:
            pass

        # 2. ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ ì‹œë„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        local_font_paths = [
            os.path.join(script_dir, "font", "Pretendard-Regular.otf"),  # font/
            os.path.join(script_dir, "fonts", "Pretendard-Regular.otf"),  # fonts/
            os.path.join(
                script_dir, "..", "font", "Pretendard-Regular.otf"
            ),  # ìƒìœ„ ë””ë ‰í† ë¦¬
            os.path.join(
                script_dir, "..", "fonts", "Pretendard-Regular.otf"
            ),  # ìƒìœ„ ë””ë ‰í† ë¦¬
        ]

        for local_path in local_font_paths:
            if os.path.exists(local_path):
                font_search_paths.append(("local", local_path))
                break  # ì²« ë²ˆì§¸ë¡œ ì°¾ì€ ê²ƒë§Œ ì‚¬ìš©

        # 3. ì‹œìŠ¤í…œ ì „ì—­ì—ì„œ Pretendard í°íŠ¸ ì°¾ê¸°
        try:
            # matplotlibì˜ fontManagerë¥¼ ì‚¬ìš©í•´ì„œ ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ Pretendard ì°¾ê¸°
            available_fonts = [f.name for f in fm.fontManager.ttflist]
            if "Pretendard" in available_fonts:
                font_search_paths.append(("system", "Pretendard"))
        except Exception:
            pass

        # í°íŠ¸ ë¡œë”© ì‹œë„
        for source_type, font_path in font_search_paths:
            try:
                if source_type in ["bundled (files)"]:
                    with importlib.resources.as_file(font_path) as font_file_path:
                        fm.fontManager.addfont(str(font_file_path))
                        prop = fm.FontProperties(fname=str(font_file_path))
                        font_name_pretendard = prop.get_name()
                        plt.rcParams["font.family"] = font_name_pretendard
                        font_loaded_pretendard = True
                        # Font loading success (debug level, not critical)
                        pass
                        break
                elif source_type in ["bundled (path)"]:
                    with font_path as font_file_path:
                        fm.fontManager.addfont(str(font_file_path))
                        prop = fm.FontProperties(fname=str(font_file_path))
                        font_name_pretendard = prop.get_name()
                        plt.rcParams["font.family"] = font_name_pretendard
                        font_loaded_pretendard = True
                        # Font loading success (debug level, not critical)
                        pass
                        break
                elif source_type == "local":
                    fm.fontManager.addfont(font_path)
                    prop = fm.FontProperties(fname=font_path)
                    font_name_pretendard = prop.get_name()
                    plt.rcParams["font.family"] = font_name_pretendard
                    font_loaded_pretendard = True
                    print(f"Pretendard í°íŠ¸ ë¡œë”© ì„±ê³µ ({source_type}): {font_path}")
                    break
                elif source_type == "system":
                    plt.rcParams["font.family"] = "Pretendard"
                    font_loaded_pretendard = True
                    print(
                        f"Pretendard í°íŠ¸ ë¡œë”© ì„±ê³µ ({source_type}): ì‹œìŠ¤í…œ ì„¤ì¹˜ëœ í°íŠ¸"
                    )
                    break
            except Exception:
                # Font loading failure (not critical, suppress message)
                pass
                continue

    except Exception:
        # Font search error (not critical, suppress)
        pass

    # Pretendard ë¡œë”© ì‹¤íŒ¨ ì‹œ ì‹œìŠ¤í…œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
    if not font_loaded_pretendard:
        # Pretendard font not found, using system default (suppress message)
        pass
        if system == "Windows":
            font_path_win = "C:/Windows/Fonts/malgun.ttf"
            if os.path.exists(font_path_win):
                font_prop = fm.FontProperties(fname=font_path_win)
                plt.rcParams["font.family"] = font_prop.get_name()
                pass  # System font loaded
            else:
                plt.rcParams["font.family"] = "Malgun Gothic"
                pass  # Malgun Gothic fallback
        elif system == "Darwin":
            plt.rcParams["font.family"] = "AppleGothic"
            pass  # AppleGothic
        elif system == "Linux":
            plt.rcParams["font.family"] = "NanumGothic"
            pass  # NanumGothic
        else:
            pass  # Unknown system, using matplotlib default


def get_pretendard_font_for_gui():
    """GUIì—ì„œ ì‚¬ìš©í•  Pretendard í°íŠ¸ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # 1. íŒ¨í‚¤ì§€ ë‚´ í°íŠ¸ ì‹œë„
        try:
            if hasattr(importlib.resources, "files"):
                try:
                    font_resource = (
                        importlib.resources.files("impulcifer_py313")
                        .joinpath("font")
                        .joinpath("Pretendard-Regular.otf")
                    )
                    with importlib.resources.as_file(font_resource) as font_file_path:
                        return str(font_file_path)
                except (FileNotFoundError, ModuleNotFoundError):
                    pass

            elif hasattr(importlib.resources, "path"):
                try:
                    with importlib.resources.path(
                        "impulcifer_py313.font", "Pretendard-Regular.otf"
                    ) as font_file_path:
                        return str(font_file_path)
                except (FileNotFoundError, ModuleNotFoundError):
                    pass
        except ImportError:
            pass

        # 2. ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ ì‹œë„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        local_font_paths = [
            os.path.join(script_dir, "font", "Pretendard-Regular.otf"),
            os.path.join(script_dir, "fonts", "Pretendard-Regular.otf"),
            os.path.join(script_dir, "..", "font", "Pretendard-Regular.otf"),
            os.path.join(script_dir, "..", "fonts", "Pretendard-Regular.otf"),
        ]

        for local_path in local_font_paths:
            if os.path.exists(local_path):
                return local_path

        # 3. ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ Pretendard ì‚¬ìš©
        try:
            available_fonts = [f.name for f in fm.fontManager.ttflist]
            if "Pretendard" in available_fonts:
                return "Pretendard"  # ì‹œìŠ¤í…œ í°íŠ¸ ì´ë¦„ ë°˜í™˜
        except Exception:
            pass

    except Exception:
        pass  # GUI font search error (not critical)

    return None


set_matplotlib_font()  # í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ í°íŠ¸ ì„¤ì • ì‹¤í–‰


# íë¹… ìŠ¤í”Œë¼ì¸ ë³´ê°„ ì ìš© í—¬í¼ í•¨ìˆ˜
def _apply_cubic_interp(
    fr_obj, target_freqs, fallback_interpolate_method_ref, operation_description=""
):
    """FrequencyResponse ê°ì²´ì— íë¹… ìŠ¤í”Œë¼ì¸ ë³´ê°„ì„ ì ìš©í•©ë‹ˆë‹¤.
    ì‹¤íŒ¨ ì‹œ ì œê³µëœ í´ë°± ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if fr_obj is None:
        return

    source_freqs = fr_obj.frequency
    source_raw = fr_obj.raw
    fr_obj.name if hasattr(fr_obj, "name") else "FrequencyResponse object"

    if (
        len(source_freqs) > 3 and len(source_raw) > 3
    ):  # interp1d 'cubic'ì€ ìµœì†Œ 4ê°œì˜ í¬ì¸íŠ¸ í•„ìš”
        unique_src_freqs, unique_indices = np.unique(source_freqs, return_index=True)
        unique_src_raw = source_raw[unique_indices]

        if len(unique_src_freqs) > 3:
            try:
                # ê²½ê³„ê°’ìœ¼ë¡œ fill_valueë¥¼ ì„¤ì •í•˜ì—¬ ì™¸ì‚½ ì‹œ ì•ˆì •ì„± í™•ë³´
                fill_val = (unique_src_raw[0], unique_src_raw[-1])
                interp_func = interp1d(
                    unique_src_freqs,
                    unique_src_raw,
                    kind="cubic",
                    bounds_error=False,
                    fill_value=fill_val,
                )

                new_raw = interp_func(target_freqs)
                fr_obj.raw = new_raw
                fr_obj.frequency = target_freqs.copy()
                # print(f"Successfully applied cubic interpolation{desc}.") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
                return True  # ì„±ê³µ
            except ValueError:
                # Cubic interpolation failed, using fallback (suppress message)
                pass
        else:
            # Not enough unique data points (suppress warning)
            pass
    else:
        # Not enough data points for cubic interpolation (suppress warning)
        pass

    # íë¹… ë³´ê°„ ì‹¤íŒ¨ ì‹œ í´ë°±
    try:
        fallback_interpolate_method_ref()
        # print(f"Fallback interpolation applied{desc}.") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
    except Exception:
        # Error in fallback interpolation (suppress error)
        pass
    return False  # ì‹¤íŒ¨ ë˜ëŠ” í´ë°± ì‚¬ìš©


def main(
    dir_path=None,
    test_signal=None,
    room_target=None,
    room_mic_calibration=None,
    headphone_compensation_file=None,
    fs=None,
    plot=False,
    channel_balance=None,
    decay=None,
    target_level=None,
    fr_combination_method="average",
    specific_limit=20000,
    generic_limit=1000,
    bass_boost_gain=0.0,
    bass_boost_fc=105,
    bass_boost_q=0.76,
    tilt=0.0,
    do_room_correction=True,
    do_headphone_compensation=True,
    do_equalization=True,
    # PR3ì—ì„œ ì¶”ê°€/ë³€ê²½ëœ íŒŒë¼ë¯¸í„° (í•­ëª© 4, 6, 7)
    head_ms=1,  # --c ì˜µì…˜ì— í•´ë‹¹ (ê¸°ë³¸ê°’ 1ms)
    jamesdsp=False,
    hangloose=False,
    interactive_plots=False,
    # ë§ˆì´í¬ í¸ì°¨ ë³´ì • íŒŒë¼ë¯¸í„° ì¶”ê°€ (v2.0)
    microphone_deviation_correction=False,
    mic_deviation_strength=0.7,
    mic_deviation_phase_correction=True,
    mic_deviation_adaptive_correction=True,
    mic_deviation_anatomical_validation=True,
    # TrueHD ë ˆì´ì•„ì›ƒ ê´€ë ¨ íŒŒë¼ë¯¸í„° ì¶”ê°€
    output_truehd_layouts=False,
):
    """"""
    logger = get_logger()

    # Calculate total steps for progress tracking
    total_steps = 10  # Base steps: estimator, target, hrir, normalize, crop, write base files, plot results
    if do_room_correction:
        total_steps += 1
    if do_headphone_compensation:
        total_steps += 1
    if do_equalization:
        total_steps += 1
    if do_headphone_compensation or do_room_correction or do_equalization:
        total_steps += 1  # Equalizing
    if decay:
        total_steps += 1
    if channel_balance:
        total_steps += 1
    if plot:
        total_steps += 5  # Pre/post plots + additional plots
    if microphone_deviation_correction:
        total_steps += 1
    if interactive_plots:
        total_steps += 1
    if fs is not None:
        total_steps += 1
    if output_truehd_layouts:
        total_steps += 1
    if jamesdsp:
        total_steps += 1
    if hangloose:
        total_steps += 1

    logger.set_total_steps(total_steps)
    logger.info(f"Starting BRIR generation with {total_steps} processing steps")

    if plot:
        try:
            import seaborn as sns

            sns.set_theme(style="whitegrid")
            logger.debug("Seaborn style applied to plots")
        except ImportError:
            logger.debug("Seaborn not installed, using default matplotlib style")

    if dir_path is None or not os.path.isdir(dir_path):
        raise NotADirectoryError(f'Given dir path "{dir_path}"" is not a directory.')

    # Dir path as absolute
    dir_path = os.path.abspath(dir_path)

    # Impulse response estimator
    logger.step("Creating impulse response estimator")
    estimator = open_impulse_response_estimator(dir_path, file_path=test_signal)

    # Room correction frequency responses
    room_frs = None
    if do_room_correction:
        logger.step("Running room correction")
        _, room_frs = room_correction(
            estimator,
            dir_path,
            target=room_target,
            mic_calibration=room_mic_calibration,
            fr_combination_method=fr_combination_method,
            specific_limit=specific_limit,
            generic_limit=generic_limit,
            plot=plot,
        )

    # Headphone compensation frequency responses
    hp_left, hp_right = None, None
    if do_headphone_compensation:
        logger.step("Running headphone compensation")
        hp_left, hp_right = headphone_compensation(
            estimator, dir_path, headphone_compensation_file
        )

    # Equalization
    eq_left, eq_right = None, None
    if do_equalization:
        logger.step("Creating headphone equalization")
        eq_left, eq_right = equalization(estimator, dir_path)

    # Bass boost and tilt
    logger.step("Creating frequency response target")
    target = create_target(
        estimator, bass_boost_gain, bass_boost_fc, bass_boost_q, tilt
    )

    # HRIR measurements
    logger.step("Opening binaural measurements")
    hrir = open_binaural_measurements(estimator, dir_path)

    # Normalize gain
    logger.step("Normalizing gain")
    applied_gain = hrir.normalize(
        peak_target=None if target_level is not None else -0.1, avg_target=target_level
    )

    # Write info and stats in readme (gain ê°’ ì „ë‹¬ ì¶”ê°€)
    readme_content = write_readme(
        os.path.join(dir_path, "README.md"), hrir, fs, estimator, applied_gain
    )
    if readme_content:
        logger.info(readme_content)

    if plot:
        # Plot graphs pre processing
        os.makedirs(os.path.join(dir_path, "plots", "pre"), exist_ok=True)
        logger.step("Plotting BRIR graphs before processing")
        hrir.plot(dir_path=os.path.join(dir_path, "plots", "pre"))

    # Crop noise and harmonics from the beginning
    logger.step("Cropping impulse responses")
    hrir.crop_heads(head_ms=head_ms)

    # PR3ì—ì„œ ì¶”ê°€ëœ align_ipsilateral_all í˜¸ì¶œ (í•­ëª© 2)
    # SPEAKER_NAMESë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ constants.pyì˜ ë³€ê²½ì´ ì„ í–‰ë˜ì–´ì•¼ í•¨
    hrir.align_ipsilateral_all(
        speaker_pairs=[
            ("FL", "FR"),
            ("SL", "SR"),
            ("BL", "BR"),
            ("TFL", "TFR"),
            ("TSL", "TSR"),
            ("TBL", "TBR"),
            ("FC", "FC"),
            ("WL", "WR"),
        ],  # FC, WL, WR ìŒì€ ì ì ˆíˆ ìˆ˜ì • í•„ìš”í•  ìˆ˜ ìˆìŒ
        segment_ms=30,
    )

    # Crop noise from the tail
    hrir.crop_tails()

    # ë§ˆì´í¬ ì°©ìš© í¸ì°¨ ë³´ì • v2.0
    if microphone_deviation_correction:
        logger.step("Correcting microphone deviation v2.0")
        mic_deviation_plot_dir = os.path.join(dir_path, "plots") if plot else None
        hrir.correct_microphone_deviation(
            correction_strength=mic_deviation_strength,
            enable_phase_correction=mic_deviation_phase_correction,
            enable_adaptive_correction=mic_deviation_adaptive_correction,
            enable_anatomical_validation=mic_deviation_anatomical_validation,
            plot_analysis=plot,
            plot_dir=mic_deviation_plot_dir,
        )

    # Write multi-channel WAV file with sine sweeps for debugging
    hrir.write_wav(os.path.join(dir_path, "responses.wav"))

    # Equalize all
    if do_headphone_compensation or do_room_correction or do_equalization:
        logger.step("Equalizing")

        # Optimization A1: Pre-generate common frequency array to reduce allocations
        common_freq = FrequencyResponse.generate_frequencies(
            f_step=1.01, f_min=10, f_max=estimator.fs / 2
        )

        if PARALLEL_PROCESSING_AVAILABLE and len(hrir.irs) > 4:
            # Python 3.14 ë³‘ë ¬ ì²˜ë¦¬: ê° ìŠ¤í”¼ì»¤ ì±„ë„ ì´í€„ë¼ì´ì œì´ì…˜
            logger.info(f"  ğŸš€ ë³‘ë ¬ ì´í€„ë¼ì´ì œì´ì…˜ ì‹œì‘ ({len(hrir.irs)} ì±„ë„)")

            def equalize_speaker_pair(speaker, pair):
                """ê° ìŠ¤í”¼ì»¤ ì±„ë„ì— ì´í€„ë¼ì´ì œì´ì…˜ ì ìš©"""
                for side, ir in pair.items():
                    # Reuse pre-generated frequency array
                    fr = FrequencyResponse(
                        name=f"{speaker}-{side} eq",
                        frequency=common_freq.copy(),
                        raw=0,
                        error=0,
                    )

                    # ë£¸ ë³´ì • ì ìš©
                    if (
                        room_frs is not None
                        and speaker in room_frs
                        and side in room_frs[speaker]
                    ):
                        fr.error += room_frs[speaker][side].error

                    # í—¤ë“œí° ë³´ì • ì ìš©
                    hp_eq = hp_left if side == "left" else hp_right
                    if hp_eq is not None:
                        fr.error += hp_eq.error

                    # ì¶”ê°€ EQ ì ìš©
                    eq = eq_left if side == "left" else eq_right
                    if eq is not None and isinstance(eq, FrequencyResponse):
                        fr.error += eq.error

                    # Remove bass and tilt target from the error
                    fr.error -= target.raw

                    # Equalize
                    eq_result, _, _, _, _, _, _, _, _, _ = fr.equalize(
                        max_gain=40,
                        treble_f_lower=10000,
                        treble_f_upper=estimator.fs / 2,
                        window_size=1 / 3,
                        treble_window_size=1 / 5,
                    )

                    # Create FIR filter and equalize
                    fir = fr.minimum_phase_impulse_response(
                        fs=estimator.fs, normalize=False, f_res=5
                    )

                    # ì‹¤ì œ FIR í•„í„° ì ìš©
                    ir.equalize(fir)

                return pair

            # ë³‘ë ¬ ì‹¤í–‰
            hrir.irs = parallel_process_dict(
                equalize_speaker_pair, hrir.irs, use_threads=True
            )

            if is_free_threaded_available():
                logger.info("  âœ… Free-Threaded ë³‘ë ¬ ì´í€„ë¼ì´ì œì´ì…˜ ì™„ë£Œ")

        else:
            # ìˆœì°¨ ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
            for speaker, pair in hrir.irs.items():
                for side, ir in pair.items():
                    # Reuse pre-generated frequency array
                    fr = FrequencyResponse(
                        name=f"{speaker}-{side} eq",
                        frequency=common_freq.copy(),
                        raw=0,
                        error=0,
                    )

                    # ë£¸ ë³´ì • ì ìš©
                    if (
                        room_frs is not None
                        and speaker in room_frs
                        and side in room_frs[speaker]
                    ):
                        # Room correction
                        fr.error += room_frs[speaker][side].error

                    # í—¤ë“œí° ë³´ì • ì ìš©
                    hp_eq = hp_left if side == "left" else hp_right
                    if hp_eq is not None:
                        # Headphone compensation
                        fr.error += hp_eq.error

                    # ì¶”ê°€ EQ ì ìš©
                    eq = eq_left if side == "left" else eq_right
                    if eq is not None and isinstance(eq, FrequencyResponse):
                        # Equalization
                        fr.error += eq.error

                    # Remove bass and tilt target from the error
                    fr.error -= target.raw

                    # Optimization A5: Remove redundant smoothen call
                    # (equalize() method calls smoothen internally)
                    # fr.smoothen(window_size=1/3, treble_window_size=1/5)

                    # Equalize
                    eq_result, _, _, _, _, _, _, _, _, _ = fr.equalize(
                        max_gain=40,
                        treble_f_lower=10000,
                        treble_f_upper=estimator.fs / 2,
                        window_size=1 / 3,
                        treble_window_size=1 / 5,
                    )

                    # Create FIR filter and equalize
                    fir = fr.minimum_phase_impulse_response(
                        fs=estimator.fs, normalize=False, f_res=5
                    )

                    # ì‹¤ì œ FIR í•„í„° ì ìš©
                    ir.equalize(fir)

    # Adjust decay time
    if decay:
        logger.step("Adjusting decay time")
        for speaker, pair in hrir.irs.items():
            for side, ir in pair.items():
                if speaker in decay:
                    ir.adjust_decay(decay[speaker])

    # Correct channel balance
    if channel_balance is not None:
        logger.step("Correcting channel balance")
        hrir.correct_channel_balance(channel_balance)

    if plot:
        logger.step("Plotting BRIR graphs after processing")
        # Convolve test signal, re-plot waveform and spectrogram
        for speaker, pair in hrir.irs.items():
            for side, ir in pair.items():
                ir.recording = ir.convolve(estimator.test_signal)
        # Plot post processing
        hrir.plot(os.path.join(dir_path, "plots", "post"))

    # Plot results, always
    logger.step("Plotting results")
    hrir.plot_result(os.path.join(dir_path, "plots"))

    # PR4: ì–‘ì´ ì‘ë‹µ ì„í„ìŠ¤ ì˜¤ë²„ë ˆì´ í”Œë¡¯ ì¶”ê°€
    if plot:
        logger.step("Plotting additional analysis graphs")
        hrir.plot_interaural_impulse_overlay(
            os.path.join(dir_path, "plots", "interaural_overlay")
        )
        hrir.plot_ild(os.path.join(dir_path, "plots", "ild"))
        hrir.plot_ipd(os.path.join(dir_path, "plots", "ipd"))
        hrir.plot_iacc(os.path.join(dir_path, "plots", "iacc"))
        hrir.plot_etc(os.path.join(dir_path, "plots", "etc"))

    # ì¸í„°ë™í‹°ë¸Œ í”Œë¡¯ ìƒì„± (ì¶”ê°€)
    if interactive_plots:
        logger.step("Generating interactive plots")
        interactive_plot_dir = os.path.join(dir_path, "interactive_plots")
        os.makedirs(interactive_plot_dir, exist_ok=True)

        panels = []
        plot_functions_map = {
            "Interaural Overlay": hrir.generate_interaural_impulse_overlay_bokeh_layout,
            "ILD": hrir.generate_ild_bokeh_layout,
            "IPD": hrir.generate_ipd_bokeh_layout,
            "IACC": hrir.generate_iacc_bokeh_layout,
            "ETC": hrir.generate_etc_bokeh_layout,
            "Result Overview": hrir.generate_result_bokeh_figure,
        }

        for title, func in plot_functions_map.items():
            try:
                plot_obj = func()
                if plot_obj:
                    # Bokeh 3.x ì—ì„œëŠ” Panelì´ TabPanelë¡œ ì´ë¦„ ë³€ê²½ë¨
                    panel = TabPanel(
                        child=plot_obj, title=title
                    )  # ìˆ˜ì •: Panel -> TabPanel
                    panels.append(panel)
                else:
                    logger.debug(f"Skipping {title} plot as no data was generated")
            except Exception as e:
                logger.warning(f"Error generating interactive plot for {title}: {e}")

        if panels:
            tabs = Tabs(tabs=panels, sizing_mode="stretch_both")
            output_html_path = os.path.join(
                interactive_plot_dir, "interactive_summary.html"
            )
            bokeh_output_file(
                output_html_path, title="Interactive Plot Summary"
            )  # bokeh_output_file ì‚¬ìš©
            bokeh_save(tabs)  # bokeh_save ì‚¬ìš©
            logger.success(f"Interactive plot summary saved to {output_html_path}")
        else:
            logger.warning("No interactive plots were generated")

    # Re-sample
    if fs is not None and fs != hrir.fs:
        logger.step(f"Resampling BRIR to {fs} Hz")
        hrir.resample(fs)
        hrir.normalize(
            peak_target=None if target_level is not None else -0.1,
            avg_target=target_level,
        )

    # Write multi-channel WAV file with standard track order
    logger.step("Writing BRIRs")
    hrir.write_wav(os.path.join(dir_path, "hrir.wav"))

    # Write multi-channel WAV file with HeSuVi track order
    hrir.write_wav(os.path.join(dir_path, "hesuvi.wav"), track_order=HESUVI_TRACK_ORDER)

    # TrueHD ë ˆì´ì•„ì›ƒ ì¶œë ¥ (ìƒˆë¡œ ì¶”ê°€)
    if output_truehd_layouts:
        logger.step("Generating TrueHD layouts")

        # í•„ìš”í•œ ì±„ë„ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìë™ ìƒì„±í•˜ëŠ” ë¡œì§ ì œê±°
        # if auto_generate_channels:
        #     generated_channels = generate_missing_channels(hrir, auto_generate_channels)
        #     if generated_channels:
        #         logger.info(f'Generated channels: {generated_channels}')

        # 11ì±„ë„ (7.0.4) ë ˆì´ì•„ì›ƒ ìƒì„±
        valid_11ch, count_11ch, msg_11ch = validate_channel_requirements(
            hrir, TRUEHD_11CH_ORDER, min_channels=8
        )
        if valid_11ch:
            available_11ch = get_available_channels_for_layout(hrir, TRUEHD_11CH_ORDER)
            track_order_11ch = create_truehd_layout_track_order(available_11ch)

            output_path_11ch = os.path.join(
                dir_path, f"truehd_11ch_{len(available_11ch)}ch.wav"
            )
            hrir.write_wav(output_path_11ch, track_order=track_order_11ch)
            logger.success(f"Generated 11-channel TrueHD layout: {output_path_11ch}")
        else:
            logger.warning(f"Cannot generate 11-channel layout: {msg_11ch}")

        # 13ì±„ë„ (7.0.6) ë ˆì´ì•„ì›ƒ ìƒì„±
        valid_13ch, count_13ch, msg_13ch = validate_channel_requirements(
            hrir, TRUEHD_13CH_ORDER, min_channels=10
        )
        if valid_13ch:
            available_13ch = get_available_channels_for_layout(hrir, TRUEHD_13CH_ORDER)
            track_order_13ch = create_truehd_layout_track_order(available_13ch)

            output_path_13ch = os.path.join(
                dir_path, f"truehd_13ch_{len(available_13ch)}ch.wav"
            )
            hrir.write_wav(output_path_13ch, track_order=track_order_13ch)
            logger.success(f"Generated 13-channel TrueHD layout: {output_path_13ch}")
        else:
            logger.warning(f"Cannot generate 13-channel layout: {msg_13ch}")

    # PR3 jamesdsp ë¡œì§ ì¶”ê°€ (í•­ëª© 6)
    if jamesdsp:
        logger.step("Generating JamesDSP output")

        # ì „ì²´ HRIR ë³µì‚¬ í›„ FL/FR ì™¸ ëª¨ë“  ì±„ë„ ì œê±°
        dsp_hrir = copy.deepcopy(hrir)
        for sp in list(dsp_hrir.irs.keys()):
            if sp not in ["FL", "FR"]:
                del dsp_hrir.irs[sp]

        # normalize ë‚´ë¶€ì˜ printë¬¸ ì¶œë ¥ì„ ìˆ¨ê¸°ê¸° ìœ„í•´ stdout ë¦¬ë””ë ‰ì…˜
        # target_level ë³€ìˆ˜ê°€ main í•¨ìˆ˜ ìŠ¤ì½”í”„ì— ìˆì–´ì•¼ í•¨
        with contextlib.redirect_stdout(io.StringIO()):
            dsp_hrir.normalize(
                peak_target=None if target_level is not None else -0.1,
                avg_target=target_level,
            )

        # FL-L, FL-R, FR-L, FR-R ìˆœì„œë¡œ íŒŒì¼ ìƒì„±
        jd_order = ["FL-left", "FL-right", "FR-left", "FR-right"]
        out_path = os.path.join(dir_path, "jamesdsp.wav")
        dsp_hrir.write_wav(out_path, track_order=jd_order)
        logger.success(f"JamesDSP IR file created: {out_path}")

    # PR3 hangloose ë¡œì§ ì¶”ê°€ (í•­ëª© 7)
    if hangloose:
        logger.step("Generating Hangloose Convolver output")
        output_dir = os.path.join(dir_path, "Hangloose")
        os.makedirs(output_dir, exist_ok=True)

        # Hrir.wav ê¸°ì¤€ ìµœëŒ€ ì±„ë„ ìˆœì„œ (constants.pyì˜ SPEAKER_NAMES ìˆœì„œì™€ ì¼ì¹˜ì‹œí‚¤ëŠ” ê²ƒì´ ì¢‹ì„ ìˆ˜ ìˆìŒ)
        # PR3ì˜ full_orderëŠ” LFEë¥¼ í¬í•¨í•˜ë‚˜, í˜„ì¬ SPEAKER_NAMESì—ëŠ” LFEê°€ ì—†ìŒ.
        # ì—¬ê¸°ì„œëŠ” hrir ê°ì²´ì— ìˆëŠ” ìŠ¤í”¼ì»¤ë§Œ ì‚¬ìš©í•˜ë„ë¡ ë‹¨ìˆœí™”.
        processed_speakers = [sp for sp in SPEAKER_NAMES if sp in hrir.irs]

        for sp in processed_speakers:
            single_hrir = copy.deepcopy(hrir)
            for other_sp in list(single_hrir.irs.keys()):
                if other_sp != sp:
                    del single_hrir.irs[other_sp]

            # ê° ìŠ¤í”¼ì»¤ì— ëŒ€í•´ normalizeë¥¼ ë‹¤ì‹œ ìˆ˜í–‰í• ì§€ ì—¬ë¶€ëŠ” PRì˜ ì˜ë„ì— ë”°ë¼ ê²°ì •.
            # ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ê³  ì›ë³¸ hrirì˜ ì •ê·œí™” ìƒíƒœë¥¼ ë”°ë¦„.

            track_order = [f"{sp}-left", f"{sp}-right"]
            out_path = os.path.join(output_dir, f"{sp}.wav")
            single_hrir.write_wav(out_path, track_order=track_order)
            logger.info(f"Created Hangloose file: {sp}.wav")

        logger.success(f"Hangloose Convolver files created in {output_dir}")

        # PR3ì˜ LFE ì±„ë„ ìƒì„± ë¡œì§ì€ FL, FRì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë¯€ë¡œ, í•„ìš”ì‹œ ì—¬ê¸°ì— ì¶”ê°€ êµ¬í˜„.
        # ì˜ˆì‹œ: if 'FL' in processed_speakers and 'FR' in processed_speakers:
        # LFE ìƒì„± ë¡œì§ ...


def open_impulse_response_estimator(dir_path, file_path=None):
    """Opens impulse response estimator from a file

    Args:
        dir_path: Path to directory
        file_path: Explicitly given (if any) path to impulse response estimator Pickle or test signal WAV file,
                  or a simple name/number for predefined test signals

    Returns:
        ImpulseResponseEstimator instance
    """
    # í…ŒìŠ¤íŠ¸ ì‹ í˜¸ê°€ ìˆ«ìë‚˜ ì´ë¦„ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš°
    if file_path in TEST_SIGNALS:
        # íŒ¨í‚¤ì§€ ë‚´ ë°ì´í„° í´ë”ì—ì„œ í•´ë‹¹ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
        test_signal_name = TEST_SIGNALS[file_path]
        test_signal_path = os.path.join(get_data_path(), test_signal_name)

        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if os.path.isfile(test_signal_path):
            file_path = test_signal_path
        else:
            # íŒ¨í‚¤ì§€ ë‚´ íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¡œì»¬ data í´ë”ì—ì„œ ì‹œë„
            local_path = os.path.join(
                os.path.dirname(os.path.abspath(__file__)), "data", test_signal_name
            )
            if os.path.isfile(local_path):
                file_path = local_path
            else:
                logger = get_logger()
                logger.warning(
                    f"Test signal '{file_path}' ({test_signal_name}) not found. Using local file"
                )

    if file_path is None:
        # Test signal not explicitly given, try Pickle first then WAV
        if os.path.isfile(os.path.join(dir_path, "test.pkl")):
            file_path = os.path.join(dir_path, "test.pkl")
        elif os.path.isfile(os.path.join(dir_path, "test.wav")):
            file_path = os.path.join(dir_path, "test.wav")
        else:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ì‚¬ìš© (íŒ¨í‚¤ì§€ ë‚´ë¶€ ë˜ëŠ” ë¡œì»¬)
            default_signal_name = TEST_SIGNALS["default"]
            default_signal_path = os.path.join(get_data_path(), default_signal_name)

            if os.path.isfile(default_signal_path):
                file_path = default_signal_path
            else:
                # íŒ¨í‚¤ì§€ ë‚´ íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¡œì»¬ data í´ë”ì—ì„œ ì‹œë„
                local_path = os.path.join(
                    os.path.dirname(os.path.abspath(__file__)),
                    "data",
                    default_signal_name,
                )
                if os.path.isfile(local_path):
                    file_path = local_path
                else:
                    raise FileNotFoundError(
                        f"ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹ í˜¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {default_signal_name}"
                    )

    if re.match(r"^.+\.wav$", file_path, flags=re.IGNORECASE):
        # Test signal is WAV file
        estimator = ImpulseResponseEstimator.from_wav(file_path)
    elif re.match(r"^.+\.pkl$", file_path, flags=re.IGNORECASE):
        # Test signal is Pickle file
        estimator = ImpulseResponseEstimator.from_pickle(file_path)
    elif re.match(r"^.+\.(mlp|thd|truehd)$", file_path, flags=re.IGNORECASE):
        # Test signal is TrueHD/MLP file - convert to temporary WAV first
        if not check_ffmpeg_available():
            raise RuntimeError(
                "TrueHD/MLP íŒŒì¼ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤. FFmpegë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            )

        if not is_truehd_file(file_path):
            raise ValueError(f"íŒŒì¼ì´ ìœ íš¨í•œ TrueHD/MLP í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {file_path}")

        logger = get_logger()
        logger.info(f"Converting TrueHD/MLP file to WAV: {file_path}")
        temp_wav_path, channel_info = convert_truehd_to_wav(file_path)

        try:
            estimator = ImpulseResponseEstimator.from_wav(temp_wav_path)
        finally:
            # Clean up temporary file
            if os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)
    else:
        raise TypeError(
            f'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í™•ì¥ì: "{file_path}"\nìœ íš¨í•œ íŒŒì¼ í™•ì¥ì: .wav, .pkl, .mlp, .thd, .truehd'
        )

    return estimator


def equalization(estimator, dir_path):
    """Reads equalization FIR filter or CSV settings

    Args:
        estimator: ImpulseResponseEstimator
        dir_path: Path to directory

    Returns:
        - Left side FIR as Numpy array or FrequencyResponse or None
        - Right side FIR as Numpy array or FrequencyResponse or None
    """
    if os.path.isfile(os.path.join(dir_path, "eq.wav")):
        logger = get_logger()
        logger.warning("eq.wav is no longer supported, use eq.csv!")
    # Default for both sides
    eq_path = os.path.join(dir_path, "eq.csv")
    eq_fr = None
    if os.path.isfile(eq_path):
        eq_fr = FrequencyResponse.read_from_csv(eq_path)

    # Left
    left_path = os.path.join(dir_path, "eq-left.csv")
    left_fr = None
    if os.path.isfile(left_path):
        left_fr = FrequencyResponse.read_from_csv(left_path)
    elif eq_fr is not None:
        left_fr = eq_fr
    if left_fr is not None:
        # left_fr.interpolate(f_step=1.01, f_min=10, f_max=estimator.fs / 2)
        new_freqs_left = FrequencyResponse.generate_frequencies(
            f_step=1.01, f_min=10, f_max=estimator.fs / 2
        )
        _apply_cubic_interp(
            left_fr,
            new_freqs_left,
            lambda: left_fr.interpolate(f_step=1.01, f_min=10, f_max=estimator.fs / 2),
            "left equalization curve",
        )

    # Right
    right_path = os.path.join(dir_path, "eq-right.csv")
    right_fr = None
    if os.path.isfile(right_path):
        right_fr = FrequencyResponse.read_from_csv(right_path)
    elif eq_fr is not None:
        right_fr = eq_fr
    if right_fr is not None and right_fr != left_fr:
        # right_fr.interpolate(f_step=1.01, f_min=10, f_max=estimator.fs / 2)
        new_freqs_right = FrequencyResponse.generate_frequencies(
            f_step=1.01, f_min=10, f_max=estimator.fs / 2
        )
        _apply_cubic_interp(
            right_fr,
            new_freqs_right,
            lambda: right_fr.interpolate(f_step=1.01, f_min=10, f_max=estimator.fs / 2),
            "right equalization curve",
        )

    # Plot
    if left_fr is not None or right_fr is not None:
        if left_fr == right_fr:
            # Both are the same, plot only one graph
            fig, ax = plt.subplots()
            fig.set_size_inches(12, 9)
            left_fr.plot(fig=fig, ax=ax, show_fig=False)
        else:
            # Left and right are different, plot two graphs in the same figure
            fig, ax = plt.subplots(1, 2)
            fig.set_size_inches(22, 9)
            if left_fr is not None:
                left_fr.plot(fig=fig, ax=ax[0], show_fig=False)
            if right_fr is not None:
                right_fr.plot(fig=fig, ax=ax[1], show_fig=False)
        save_fig_as_png(os.path.join(dir_path, "plots", "eq.png"), fig)

    return left_fr, right_fr


def headphone_compensation(estimator, dir_path, headphone_file_path=None):
    """Equalizes HRIR tracks with headphone compensation measurement.

    Args:
        estimator: ImpulseResponseEstimator instance
        dir_path: Path to output directory
        headphone_file_path: Optional path to the headphone compensation WAV file.
                             If None, defaults to 'headphones.wav' in dir_path.

    Returns:
        None
    """
    # Read WAV file
    hp_irs = HRIR(estimator)

    # Determine the headphone file to use
    if headphone_file_path:
        # If a specific path is provided, use it
        # If it's a relative path, consider it relative to the current working directory or dir_path
        # For simplicity, we'll assume it's either absolute or relative to dir_path if not absolute
        if not os.path.isabs(headphone_file_path):
            actual_hp_file = os.path.join(dir_path, headphone_file_path)
        else:
            actual_hp_file = headphone_file_path
        logger = get_logger()

    if not os.path.exists(actual_hp_file):
        logger.warning(
            f"Specified headphone compensation file not found: {actual_hp_file}. Trying default 'headphones.wav'"
        )
        actual_hp_file = os.path.join(dir_path, "headphones.wav")  # Fallback to default
    else:
        # Default to headphones.wav in the dir_path
        actual_hp_file = os.path.join(dir_path, "headphones.wav")

    if not os.path.exists(actual_hp_file):
        logger.error(f"Headphone compensation file not found: {actual_hp_file}")
        return None, None  # Or raise an error

    logger.info(f"Using headphone compensation file: {actual_hp_file}")
    hp_irs.open_recording(actual_hp_file, speakers=["FL", "FR"])
    hp_irs.write_wav(os.path.join(dir_path, "headphone-responses.wav"))

    # Frequency responses
    left = hp_irs.irs["FL"]["left"].frequency_response()
    right = hp_irs.irs["FR"]["right"].frequency_response()

    # ë°°ì—´ ê¸¸ì´ ê²€ì¦ ë° ì¼ì¹˜ì‹œí‚¤ê¸°
    if len(left.frequency) != len(right.frequency):
        # ë‘˜ ì¤‘ ë” ì‘ì€ ê¸¸ì´ë¡œ ì¡°ì •
        min_length = min(len(left.frequency), len(right.frequency))
        left.frequency = left.frequency[:min_length]
        left.raw = left.raw[:min_length]
        right.frequency = right.frequency[:min_length]
        right.raw = right.raw[:min_length]

    # Center by left channel
    gain = left.center([100, 10000])
    right.raw += gain

    # ì €ì£¼íŒŒ ë¡¤ì˜¤í”„ ë°©ì§€ë¥¼ ìœ„í•œ íƒ€ê²Ÿ ìƒì„±
    freq = FrequencyResponse.generate_frequencies(
        f_min=10, f_max=estimator.fs / 2, f_step=1.01
    )

    # ìƒˆë¡œìš´ íƒ€ê²Ÿ: ì €ì£¼íŒŒì— 6dB ë¶€ìŠ¤íŠ¸ë¥¼ ì ìš©í•œ íƒ€ê²Ÿ
    target_raw = np.zeros(len(freq))

    # íƒ€ê²Ÿ ì‘ë‹µ ê°ì²´ ìƒì„±
    target = FrequencyResponse(
        name="headphone_compensation_target", frequency=freq, raw=target_raw
    )

    # leftì™€ rightë¥¼ íƒ€ê²Ÿì˜ ì£¼íŒŒìˆ˜ì— ë§ê²Œ ë³´ê°„
    left.copy()
    right.copy()

    _apply_cubic_interp(
        left,
        target.frequency,
        lambda: left.interpolate(f=target.frequency),
        "left headphone response",
    )
    _apply_cubic_interp(
        right,
        target.frequency,
        lambda: right.interpolate(f=target.frequency),
        "right headphone response",
    )

    # ë³´ìƒ ì ìš©
    left.compensate(target, min_mean_error=True)
    right.compensate(target, min_mean_error=True)

    # ê¸°ì¡´ í—¤ë“œí° í”Œë¡¯
    fig = plt.figure()
    gs = fig.add_gridspec(2, 3)
    fig.set_size_inches(22, 10)
    fig.suptitle("Headphones")

    # Left
    axl = fig.add_subplot(gs[0, 0])
    left.plot(fig=fig, ax=axl, show_fig=False)
    axl.set_title("Left")
    # Right
    axr = fig.add_subplot(gs[1, 0])
    right.plot(fig=fig, ax=axr, show_fig=False)
    axr.set_title("Right")
    # Sync axes
    sync_axes([axl, axr])

    # Combined
    _left = left.copy()
    _right = right.copy()
    gain_l = _left.center([100, 10000])
    gain_r = _right.center([100, 10000])
    ax = fig.add_subplot(gs[:, 1:])
    ax.plot(_left.frequency, _left.raw, linewidth=1, color="#1f77b4")
    ax.plot(_right.frequency, _right.raw, linewidth=1, color="#d62728")
    ax.plot(_left.frequency, _left.raw - _right.raw, linewidth=1, color="#680fb9")
    sl = np.logical_and(_left.frequency > 20, _left.frequency < 20000)
    stack = np.vstack([_left.raw[sl], _right.raw[sl], _left.raw[sl] - _right.raw[sl]])
    ax.set_ylim([np.min(stack) * 1.1, np.max(stack) * 1.1])
    axl.set_ylim([np.min(stack) * 1.1, np.max(stack) * 1.1])
    axr.set_ylim([np.min(stack) * 1.1, np.max(stack) * 1.1])
    ax.set_title("Comparison")
    ax.legend(
        [f"Left raw {gain_l:+.1f} dB", f"Right raw {gain_r:+.1f} dB", "Difference"],
        fontsize=8,
    )
    ax.set_xlabel("Frequency (Hz)")
    ax.semilogx()
    ax.set_xlim([20, 20000])
    ax.set_ylabel("Amplitude (dB)")
    ax.grid(True, which="major")
    ax.grid(True, which="minor")
    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter("{x:.0f}"))

    # Save headphone plots
    file_path = os.path.join(dir_path, "plots", "headphones.png")
    os.makedirs(os.path.split(file_path)[0], exist_ok=True)
    save_fig_as_png(file_path, fig)
    plt.close(fig)

    return left, right


def create_target(estimator, bass_boost_gain, bass_boost_fc, bass_boost_q, tilt):
    """Creates target frequency response with bass boost, tilt and high pass at 20 Hz"""
    # íƒ€ê²Ÿ ì£¼íŒŒìˆ˜ ì‘ë‹µ ìƒì„±
    target = FrequencyResponse(
        name="bass_and_tilt",
        frequency=FrequencyResponse.generate_frequencies(
            f_min=10, f_max=estimator.fs / 2, f_step=1.01
        ),
    )

    # ë² ì´ìŠ¤ ë¶€ìŠ¤íŠ¸ì™€ í‹¸íŠ¸ ì ìš©
    # ê¸°ë³¸ ë² ì´ìŠ¤ ë¶€ìŠ¤íŠ¸ë§Œ ì ìš© (ì¶”ê°€ ë¶€ìŠ¤íŠ¸ ì œê±°)
    target.raw = target.create_target(
        bass_boost_gain=bass_boost_gain,  # +3dB ì¶”ê°€ ë¶€ìŠ¤íŠ¸ ì œê±°
        bass_boost_fc=bass_boost_fc,
        bass_boost_q=bass_boost_q,
        tilt=tilt,
    )

    # ì €ì£¼íŒŒ ì˜ì—­ ë² ì´ìŠ¤ ë¶€ìŠ¤íŠ¸ ê°’ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
    # bass_boost_values = target.raw[:200]  # ì €ì£¼íŒŒ ì˜ì—­ë§Œ ì¶”ì¶œ
    # print("ì €ì£¼íŒŒ ì˜ì—­ Bass Boost ê°’:", bass_boost_values) # ì£¼ì„ ì²˜ë¦¬

    return target


def open_binaural_measurements(estimator, dir_path):
    """Opens binaural measurement WAV files.

    Args:
        estimator: ImpulseResponseEstimator
        dir_path: Path to directory

    Returns:
        HRIR instance
    """
    hrir = HRIR(estimator)
    pattern = r"^{pattern}\.wav$".format(pattern=SPEAKER_LIST_PATTERN)  # FL,FR.wav
    for file_name in [f for f in os.listdir(dir_path) if re.match(pattern, f)]:
        # Read the speaker names from the file name into a list
        speakers = re.search(SPEAKER_LIST_PATTERN, file_name)[0].split(",")
        # Form absolute path
        file_path = os.path.join(dir_path, file_name)
        # Open the file and add tracks to HRIR
        hrir.open_recording(file_path, speakers=speakers)
    if len(hrir.irs) == 0:
        raise ValueError("No HRIR recordings found in the directory.")
    return hrir


def write_readme(file_path, hrir, fs, estimator, applied_gain):
    """Writes info and stats to a README file and returns its content as a string.

    Args:
        file_path (str): Path to README file.
        hrir (HRIR): HRIR object.
        fs (int): Output sampling rate.
        estimator (ImpulseResponseEstimator): Estimator object for advanced stats.
        applied_gain (float): Applied gain level.

    Returns:
        str: Content of the README file.
    """
    # ê¸°ë³¸ í—¤ë” ìƒì„±
    content = "# BRIR Info\n\n"
    content += f"Processed on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}. Output sampling rate is {fs if fs is not None else hrir.fs} Hz.\n\n"

    # í•­ëª© 8: ì ìš©ëœ ë…¸ë©€ë¼ì´ì œì´ì…˜ ê²Œì¸ ì¶”ê°€
    if applied_gain is not None:
        content += "## Applied Normalization Gain\n"
        content += f"{applied_gain:.2f} dB was applied to all channels.\n\n"

    # ê¸°ì¡´ í†µê³„ í…Œì´ë¸” ìƒì„± ë¡œì§ (rt_name, table, speaker_names ë“±)
    table_data = []  # ë³€ìˆ˜ëª… ë³€ê²½ (table -> table_data)
    # SPEAKER_NAMES ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ë˜, ì—†ëŠ” ìŠ¤í”¼ì»¤ëŠ” ë’¤ë¡œ
    speaker_names_in_hrir = list(hrir.irs.keys())
    sorted_speaker_names = sorted(
        speaker_names_in_hrir,
        key=lambda x: SPEAKER_NAMES.index(x) if x in SPEAKER_NAMES else float("inf"),
    )

    final_rt_name = "Reverb"  # ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©ë  RTxx ì´ë¦„, ëª¨ë“  IR ê²€í†  í›„ ê²°ì •
    rt_values_for_naming = []

    for speaker in sorted_speaker_names:
        if speaker not in hrir.irs:
            continue
        pair = hrir.irs[speaker]

        peak_left_idx = pair["left"].peak_index()
        peak_right_idx = pair["right"].peak_index()
        itd = np.nan
        if peak_left_idx is not None and peak_right_idx is not None:
            itd = np.abs(peak_right_idx - peak_left_idx) / hrir.fs * 1e6  # us

        for side, ir_obj in pair.items():
            current_itd = 0.0
            if not np.isnan(itd):
                if speaker.endswith("L") and side == "right":
                    current_itd = itd
                elif speaker.endswith("R") and side == "left":
                    current_itd = itd

            pnr_val = np.nan
            length_ms = np.nan
            rt_val_ms = np.nan
            current_ir_rt_name = None

            peak_idx_current_ir = ir_obj.peak_index()
            if peak_idx_current_ir is not None:
                # PNR ê³„ì‚°
                peak_val_linear = np.abs(ir_obj.data[peak_idx_current_ir])
                # ë°ì´í„°ê°€ 0~1ë¡œ ì •ê·œí™”ë˜ì—ˆë‹¤ê³  ê°€ì •. ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ìµœëŒ€ê°’ìœ¼ë¡œ ë‚˜ëˆ ì•¼ í•¨.
                # peak_val_db = 20 * np.log10(peak_val_linear / np.max(np.abs(ir_obj.data)) + 1e-9) # ì¢€ ë” ì•ˆì „í•œ ë°©ì‹
                peak_val_db = 20 * np.log10(
                    peak_val_linear + 1e-9
                )  # í”¼í¬ê°’ì˜ dBFS (ìµœëŒ€ê°’ì´ 1.0ì´ë¼ê³  ê°€ì •)

                decay_params_tuple = ir_obj.decay_params()
                if decay_params_tuple:
                    noise_floor_db = decay_params_tuple[2]
                    if not np.isnan(noise_floor_db) and not np.isnan(peak_val_db):
                        pnr_val = peak_val_db - noise_floor_db

                    # Length ê³„ì‚°
                    tail_ind_calc = decay_params_tuple[
                        1
                    ]  # decay_paramsì˜ ë‘ ë²ˆì§¸ ê°’ì´ tail index (peak_idx + knee_idx)
                    if (
                        tail_ind_calc is not None
                        and tail_ind_calc > peak_idx_current_ir
                    ):
                        length_ms = (
                            (tail_ind_calc - peak_idx_current_ir) / ir_obj.fs * 1000
                        )

                # RTxx ê³„ì‚° (decay_times ì‚¬ìš©)
                # decay_times() í˜¸ì¶œ ì‹œ peak_ind ë“±ì„ ì „ë‹¬í•´ì•¼ í•  ìˆ˜ ìˆìŒ (API í™•ì¸)
                # í˜„ì¬ APIëŠ” decay_params() ë‚´ë¶€ ê°’ë“¤ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, decay_params() í˜¸ì¶œ í›„ ì‚¬ìš© ê°€ëŠ¥
                edt, rt20, rt30, rt60 = ir_obj.decay_times(
                    peak_ind=decay_params_tuple[0] if decay_params_tuple else None,
                    knee_point_ind=decay_params_tuple[1]
                    if decay_params_tuple
                    else None,
                    noise_floor=decay_params_tuple[2] if decay_params_tuple else None,
                    window_size=decay_params_tuple[3] if decay_params_tuple else None,
                )

                # ê°€ì¥ ê¸´ ìœ íš¨í•œ RTxx ê°’ ì„ íƒ
                if rt60 is not None and not np.isnan(rt60):
                    rt_val_ms = rt60 * 1000
                    current_ir_rt_name = "RT60"
                elif rt30 is not None and not np.isnan(rt30):
                    rt_val_ms = rt30 * 1000
                    current_ir_rt_name = "RT30"
                elif rt20 is not None and not np.isnan(rt20):
                    rt_val_ms = rt20 * 1000
                    current_ir_rt_name = "RT20"
                elif edt is not None and not np.isnan(edt):
                    rt_val_ms = edt * 1000
                    current_ir_rt_name = "EDT"

                if current_ir_rt_name:
                    rt_values_for_naming.append(current_ir_rt_name)

            table_data.append(
                [
                    speaker,
                    side,
                    f"{pnr_val:.1f} dB" if not np.isnan(pnr_val) else "N/A",
                    f"{current_itd:.1f} us" if not np.isnan(current_itd) else "N/A",
                    f"{length_ms:.1f} ms"
                    if length_ms is not None
                    and not np.isnan(length_ms)
                    and length_ms >= 0
                    else "N/A",  # ìŒìˆ˜ ê¸¸ì´ ë°©ì§€
                    f"{rt_val_ms:.1f} ms"
                    if rt_val_ms is not None and not np.isnan(rt_val_ms)
                    else "N/A",
                ]
            )

    # ëª¨ë“  IRì„ ì‚´í´ë³¸ í›„ ìµœì¢… RTxx ì´ë¦„ ê²°ì • (ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ìœ íš¨í•œ ì´ë¦„ ë˜ëŠ” ìš°ì„ ìˆœìœ„)
    if rt_values_for_naming:
        # ì˜ˆ: ê°€ì¥ ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚œ RTxx ì´ë¦„ ì‚¬ìš©
        from collections import Counter

        final_rt_name = Counter(rt_values_for_naming).most_common(1)[0][0]
    else:
        final_rt_name = "RTxx"  # ê¸°ë³¸ê°’

    if table_data:
        headers = ["Speaker", "Side", "PNR", "ITD", "Length", final_rt_name]
        content += tabulate(table_data, headers=headers, tablefmt="pipe")
        content += "\n\n"

    # í•­ëª© 9: ë°˜ì‚¬ìŒ ë ˆë²¨ ì¶”ê°€
    if estimator and hasattr(hrir, "calculate_reflection_levels"):
        reflection_data = hrir.calculate_reflection_levels()  # ì¸ì ì—†ì´ í˜¸ì¶œ
        if reflection_data:
            content += "## Reflection Levels (Direct vs. Early/Late)\n"
            # SPEAKER_NAMES ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ë˜, ì—†ëŠ” ìŠ¤í”¼ì»¤ëŠ” ë’¤ë¡œ
            sorted_reflection_speakers = sorted(
                reflection_data.keys(),
                key=lambda x: SPEAKER_NAMES.index(x)
                if x in SPEAKER_NAMES
                else float("inf"),
            )
            for speaker in sorted_reflection_speakers:
                if (
                    speaker not in reflection_data
                ):  # Should not happen due to sorted keys
                    continue
                sides_data = reflection_data[speaker]
                content += f"### {speaker}\n"
                if "left" in sides_data and isinstance(sides_data["left"], dict):
                    content += f"- Left Ear: Early (20-50ms): {sides_data['left'].get('early_db', np.nan):.2f} dB, Late (50-150ms): {sides_data['left'].get('late_db', np.nan):.2f} dB\n"
                if "right" in sides_data and isinstance(sides_data["right"], dict):
                    content += f"- Right Ear: Early (20-50ms): {sides_data['right'].get('early_db', np.nan):.2f} dB, Late (50-150ms): {sides_data['right'].get('late_db', np.nan):.2f} dB\n"
            content += "\n"

    # íŒŒì¼ì— ì“°ê¸°
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content)

    return content


def create_cli():
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument(
        "--dir_path",
        type=str,
        required=True,
        help="Path to directory for recordings and outputs.",
    )
    arg_parser.add_argument(
        "--test_signal",
        type=str,
        default=argparse.SUPPRESS,
        help="Path to sine sweep test signal or pickled impulse response estimator. "
        "You can also use a predefined name or number: "
        '"default"/"1" (.pkl), "sweep"/"2" (.wav), "stereo"/"3" (FL,FR), '
        '"mono-left"/"4" (FL mono), "left"/"5" (FL stereo), "right"/"6" (FR stereo).',
    )
    arg_parser.add_argument(
        "--room_target",
        type=str,
        default=argparse.SUPPRESS,
        help="Path to room target response AutoEQ style CSV file.",
    )
    arg_parser.add_argument(
        "--room_mic_calibration",
        type=str,
        default=argparse.SUPPRESS,
        help="Path to room measurement microphone calibration file.",
    )
    arg_parser.add_argument(
        "--no_room_correction",
        action="store_false",
        dest="do_room_correction",
        help="Skip room correction.",
    )
    arg_parser.add_argument(
        "--no_headphone_compensation",
        action="store_false",
        dest="do_headphone_compensation",
        help="Skip headphone compensation.",
    )
    arg_parser.add_argument(
        "--headphone_compensation_file",
        type=str,
        default=None,
        help='Path to the headphone compensation WAV file. Defaults to "headphones.wav" in dir_path.',
    )
    arg_parser.add_argument(
        "--no_equalization",
        action="store_false",
        dest="do_equalization",
        help="Skip equalization.",
    )
    arg_parser.add_argument(
        "--fs",
        type=int,
        default=argparse.SUPPRESS,
        help="Output sampling rate in Hertz.",
    )
    arg_parser.add_argument(
        "--plot", action="store_true", help="Plot graphs for debugging."
    )
    arg_parser.add_argument(
        "--interactive_plots",
        action="store_true",
        help="Generate interactive Bokeh plots in HTML files.",
    )
    arg_parser.add_argument(
        "--channel_balance",
        type=str,
        default=argparse.SUPPRESS,
        help="Channel balance correction by equalizing left and right ear results to the same "
        'level or frequency response. "trend" equalizes right side by the difference trend '
        'of right and left side. "left" equalizes right side to left side fr, "right" '
        'equalizes left side to right side fr, "avg" equalizes both to the average fr, "min" '
        "equalizes both to the minimum of left and right side frs. Number values will boost "
        'or attenuate right side relative to left side by the number of dBs. "mids" is the '
        "same as the numerical values but guesses the value automatically from mid frequency "
        "levels.",
    )
    arg_parser.add_argument(
        "--decay",
        type=str,
        default=argparse.SUPPRESS,
        help="Target decay time in milliseconds to reach -60 dB. When the natural decay time is "
        "longer than the target decay time, a downward slope will be applied to decay tail. "
        "Decay cannot be increased with this. By default no decay time adjustment is done. "
        "A comma separated list of channel name and  reverberation time pairs, separated by "
        "a colon. If only a single numeric value is given, it is used for all channels. When "
        "some channel names are give but not all, the missing channels are not affected. For "
        'example "--decay=300" or "--decay=FL:500,FC:100,FR:500,SR:700,BR:700,BL:700,SL:700" '
        'or "--decay=FC:100".',
    )
    arg_parser.add_argument(
        "--target_level",
        type=float,
        default=argparse.SUPPRESS,
        help="Target average gain level for left and right channels. This will sum together all "
        "left side impulse responses and right side impulse responses respectively and take "
        "the average gain from mid frequencies. The averaged level is then normalized to the "
        "given target level. This makes it possible to compare HRIRs with somewhat similar "
        "loudness levels. This should be negative in most cases to avoid clipping.",
    )
    arg_parser.add_argument(
        "--fr_combination_method",
        type=str,
        default="average",
        help="Method for combining frequency responses of generic room measurements if there are "
        'more than one tracks in the file. "average" will simply average the frequency'
        'responses. "conservative" will take the minimum absolute value for each frequency '
        "but only if the values in all the measurements are positive or negative at the same "
        "time.",
    )
    arg_parser.add_argument(
        "--specific_limit",
        type=float,
        default=400,
        help="Upper limit for room equalization with speaker-ear specific room measurements. "
        "Equalization will drop down to 0 dB at this frequency in the leading octave. 0 "
        "disables limit.",
    )
    arg_parser.add_argument(
        "--generic_limit",
        type=float,
        default=300,
        help="Upper limit for room equalization with generic room measurements. "
        "Equalization will drop down to 0 dB at this frequency in the leading octave. 0 "
        "disables limit.",
    )
    arg_parser.add_argument(
        "--bass_boost",
        type=str,
        default=argparse.SUPPRESS,
        help="Bass boost shelf. Sub-bass frequencies will be boosted by this amount. Can be "
        "either a single value for a gain in dB or a comma separated list of three values for "
        "parameters of a low shelf filter, where the first is gain in dB, second is center "
        "frequency (Fc) in Hz and the last is quality (Q). When only a single value (gain) is "
        "given, default values for Fc and Q are used which are 105 Hz and 0.76, respectively. "
        'For example "--bass_boost=6" or "--bass_boost=6,150,0.69".',
    )
    arg_parser.add_argument(
        "--tilt",
        type=float,
        default=argparse.SUPPRESS,
        help="Target tilt in dB/octave. Positive value (upwards slope) will result in brighter "
        "frequency response and negative value (downwards slope) will result in darker "
        "frequency response. 1 dB/octave will produce nearly 10 dB difference in "
        "desired value between 20 Hz and 20 kHz. Tilt is applied with bass boost and both "
        "will affect the bass gain.",
    )
    arg_parser.add_argument(
        "--c",
        type=float,
        default=1.0,
        dest="head_ms",
        help="Head room in milliseconds for cropping impulse response heads. Default is 1.0 (ms). (í•­ëª© 4)",
    )
    arg_parser.add_argument(
        "--jamesdsp",
        action="store_true",
        help="Generate true stereo IR file (jamesdsp.wav) for JamesDSP from FL/FR channels. (í•­ëª© 6)",
    )
    arg_parser.add_argument(
        "--hangloose",
        action="store_true",
        help="Generate separate stereo IR for each channel for Hangloose Convolver. (í•­ëª© 7)",
    )
    arg_parser.add_argument(
        "--microphone_deviation_correction",
        action="store_true",
        help="Enable microphone deviation correction v2.0 to compensate for microphone placement variations between left and right ears.",
    )
    arg_parser.add_argument(
        "--mic_deviation_strength",
        type=float,
        default=0.7,
        help="Microphone deviation correction strength (0.0-1.0). 0.0 = no correction, 1.0 = full correction. Default is 0.7.",
    )
    arg_parser.add_argument(
        "--no_mic_deviation_phase_correction",
        action="store_false",
        dest="mic_deviation_phase_correction",
        help="Disable phase correction in microphone deviation correction v2.0. (Default: enabled)",
    )
    arg_parser.add_argument(
        "--no_mic_deviation_adaptive_correction",
        action="store_false",
        dest="mic_deviation_adaptive_correction",
        help="Disable adaptive asymmetric correction in microphone deviation correction v2.0. (Default: enabled)",
    )
    arg_parser.add_argument(
        "--no_mic_deviation_anatomical_validation",
        action="store_false",
        dest="mic_deviation_anatomical_validation",
        help="Disable ITD/ILD anatomical validation in microphone deviation correction v2.0. (Default: enabled)",
    )
    arg_parser.add_argument(
        "--output_truehd_layouts", action="store_true", help="Generate TrueHD layouts."
    )
    args = vars(arg_parser.parse_args())
    if "bass_boost" in args:
        bass_boost = args["bass_boost"].split(",")
        if len(bass_boost) == 1:
            args["bass_boost_gain"] = float(bass_boost[0])
            args["bass_boost_fc"] = 105
            args["bass_boost_q"] = 0.76
        elif len(bass_boost) == 3:
            args["bass_boost_gain"] = float(bass_boost[0])
            args["bass_boost_fc"] = float(bass_boost[1])
            args["bass_boost_q"] = float(bass_boost[2])
        else:
            raise ValueError(
                '"--bass_boost" must have one value or three values separated by commas!'
            )
        del args["bass_boost"]
    if "decay" in args:
        decay = dict()
        try:
            # Single float value
            decay = {ch: float(args["decay"]) / 1000 for ch in SPEAKER_NAMES}
        except ValueError:
            # Channels separated
            for ch_t in args["decay"].split(","):
                decay[ch_t.split(":")[0].upper()] = float(ch_t.split(":")[1]) / 1000
        args["decay"] = decay
    return args


if __name__ == "__main__":
    cli_args = create_cli()
    # interactive_plots ì¸ìë¥¼ main í•¨ìˆ˜ì— ì „ë‹¬
    main(**cli_args)
